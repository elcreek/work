{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 19\n",
    "\n",
    "\n",
    "# video 27:00 \n",
    "# Y2Mate.is - Data Science Best Practices with pandas (PyCon 2019)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import argrelextrema\n",
    "import os\n",
    "\n",
    "from cycler import cycler\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "# import yfinance as yf\n",
    "# from collections import deque\n",
    "# from matplotlib.lines import Line2D\n",
    "import pandas_ta as ta\n",
    "import ccxt\n",
    "from datetime import datetime, timedelta\n",
    "import plotly.graph_objects as go\n",
    "# import inspect \n",
    "from IPython.display import display, HTML\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs\n",
    "\n",
    "dates = pd.date_range('1/1/2000', periods=8)\n",
    "\n",
    "df = pd.DataFrame(np.random.rand(8, 4), index=dates, columns=['Open', 'High', 'Low', 'Close'])\n",
    "\n",
    "#########\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'col1': ['A', 'A', 'B', np.nan, 'D', 'C'],\n",
    "    'col2': [2, 1, 9, 8, 7, 4],\n",
    "    'col3': [0, 1, 9, 4, 2, 3],\n",
    "    'col4': ['a', 'B', 'c', 'D', 'e', 'F']\n",
    "})\n",
    "\n",
    "#######\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'],\n",
    "    'style': ['cup', 'cup', 'cup', 'pack', 'pack'],\n",
    "    'rating': [4, 4, 3.5, 15, 5]\n",
    "})\n",
    "\n",
    "#######\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Notes about coding '''\n",
    "\"\"\" when you're done editing; copy the notebook file as backup \"\"\"\n",
    "\"\"\" each cell is a standalone \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Tricks \"\"\"\n",
    "\n",
    "\"\"\" to run only a small piece of code from within a cell; first run its dependecies than \n",
    "select the lines you want to run then press left mouse button and look for run selcted line  \n",
    "if teminal wont recognize code ; type py to run python inside it\"\"\"\n",
    "# line comment is ctrl + : \n",
    "# multi line comment is shift + alt + a\n",
    "# copy line(s) is shift+alt+arrow\n",
    "# \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(l) is <class list>\n",
    "\n",
    "# l.sort() ---> None\n",
    "\n",
    "# sorted(l) ---> works fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"C:\\Users\\Grant\\Desktop\\work_git\\work\\data/1d/1INCHUSDT_1d.csv\")\n",
    "\n",
    "# Input In [4]\n",
    "#     df = pd.read_csv(\"C:\\Users\\Grant\\Desktop\\work_git\\work\\data/1d/1INCHUSDT_1d.csv\")\n",
    "#                                                                                     ^\n",
    "# SyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n",
    "\n",
    "# solution add \\\n",
    "\n",
    "# df = pd.read_csv(\"C:\\\\Users\\Grant\\Desktop\\work_git\\work\\data/1d/1INCHUSDT_1d.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make yourself familliar with dataset before using it\n",
    "\n",
    "# df.dtypes\n",
    "# df.shape\n",
    "# df.head()\n",
    "# df.isna().sum()\n",
    "# df.info()\n",
    "\n",
    "# somtimes you find (! ?) inside df cells which are not recognized as nan\n",
    "# so the solutin is to use replace method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency of numbers on a list (wont work on letters)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# access keys in dict\n",
    "lst = [1,2,3,4,5,2,0,5,1,8,9,7,5,9,8,2,4]\n",
    "dct=dict(Counter(lst))\n",
    "\n",
    "list(dct)\n",
    "list(dct.values())\n",
    "\n",
    "# dct key\n",
    "list(dct)[-2]\n",
    "\n",
    "# dct value\n",
    "list(dct.values())[-2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most common element on a list\n",
    "\n",
    "lst = [1,2,3,4,5,2,0,5,1,8,9,7,5,9,8,2,4]\n",
    "\n",
    "def most_common(lst):\n",
    "    return max(set(lst), key=lst.count)\n",
    "\n",
    "most_common(lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l=[]\n",
    "# for n in range(55):\n",
    "#     best_sma(data, n)\n",
    "#     l.append(best_sma)\n",
    "\n",
    "\n",
    "#       1 l=[]\n",
    "#       2 for n in range(55):\n",
    "# ----> 3     best_sma(data, n)\n",
    "#       4     l.append(best_sma)\n",
    "\n",
    "# TypeError: 'int' object is not callable\n",
    "\n",
    "# the ^roblem is i have a var called best_sma\n",
    "# so youcant have var and function with htr same name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Missing Values\n",
    "# Pandas provides isnull(), isna() functions to detect missing values. Both of them do the same thing.\n",
    "# df.isna() returns the dataframe with boolean values indicating missing values.\n",
    "\n",
    "# You can also choose to use notna() which is just the opposite of isna().\n",
    "# df.isna().any() returns a boolean value for each column. \n",
    "# If there is at least one missing value in that column, the result is True.\n",
    "\n",
    "# df.isna().sum() returns the number of missing values in each column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1], [1, 2], [2, 3]]\n",
      "   A  B\n",
      "0  0  1\n",
      "1  1  2\n",
      "2  2  3\n",
      "   A  B\n",
      "0  0  1\n",
      "1  1  2\n",
      "2  2  3\n",
      "   A  B\n",
      "0  0  1\n",
      "1  1  2\n"
     ]
    }
   ],
   "source": [
    "# How to build a pandas DataFrame with a for-loop in Python\n",
    "import pandas as pd\n",
    "\n",
    "rows = []\n",
    "for i in range(3):\n",
    "     rows.append([i, i + 1])\n",
    "print(rows)\n",
    "\n",
    "# OUTPUT\n",
    "# [[0, 1], [1, 2], [2, 3]]\n",
    "\n",
    "dfc = pd.DataFrame(rows, columns=[\"A\", \"B\"])\n",
    "print(dfc)\n",
    "\n",
    "# OUTPUT\n",
    "#    A  B\n",
    "# 0  0  1\n",
    "# 1  1  2\n",
    "# 2  2  3\n",
    "\n",
    "# Use a list comprehension for a more compact implementation.\n",
    "\n",
    "rows = [[i, i+1] for i in range(3)]\n",
    "dfc = pd.DataFrame(rows, columns=[\"A\", \"B\"])\n",
    "print(dfc)\n",
    "\n",
    "# OUTPUT\n",
    "#    A  B\n",
    "# 0  0  1\n",
    "# 1  1  2\n",
    "# 2  2  3\n",
    "\n",
    "# USE COLUMN INDEXING TO BUILD A DATAFRAME WITH A FOR-LOOP\n",
    "\n",
    "dfc = pd.DataFrame(columns=[\"A\", \"B\"])\n",
    "for i in range(2):\n",
    "    this_column = dfc.columns[i]\n",
    "    dfc[this_column] = [i, i+1]\n",
    "\n",
    "print(dfc)\n",
    "\n",
    "# OUTPUT\n",
    "#    A  B\n",
    "# 0  0  1\n",
    "# 1  1  2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting by a column\n",
    "\n",
    "# use inplace=True to make changes permanent \n",
    "# so you could use the result with other functions\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'col1': ['A', 'A', 'B', np.nan, 'D', 'C'],\n",
    "    'col2': [2, 1, 9, 8, 7, 4],\n",
    "    'col3': [0, 1, 9, 4, 2, 3],\n",
    "    'col4': ['a', 'B', 'c', 'D', 'e', 'F']\n",
    "})\n",
    "df\n",
    "#   col1  col2  col3 col4\n",
    "# 0    A     2     0    a\n",
    "# 1    A     1     1    B\n",
    "# 2    B     9     9    c\n",
    "# 3  NaN     8     4    D\n",
    "# 4    D     7     2    e\n",
    "# 5    C     4     3    F\n",
    "\n",
    "# Sort by col1\n",
    "\n",
    "df.sort_values(by=['col1'])\n",
    "\n",
    "#   col1  col2  col3 col4\n",
    "# 0    A     2     0    a\n",
    "# 1    A     1     1    B\n",
    "# 2    B     9     9    c\n",
    "# 5    C     4     3    F\n",
    "# 4    D     7     2    e\n",
    "# 3  NaN     8     4    D\n",
    "\n",
    "# Sort by multiple columns\n",
    "\n",
    "df.sort_values(by=['col1', 'col2'])\n",
    "\n",
    "#   col1  col2  col3 col4\n",
    "# 1    A     1     1    B\n",
    "# 0    A     2     0    a\n",
    "# 2    B     9     9    c\n",
    "# 5    C     4     3    F\n",
    "# 4    D     7     2    e\n",
    "# 3  NaN     8     4    D\n",
    "\n",
    "# Sort Descending\n",
    "\n",
    "df.sort_values(by='col1', ascending=False)\n",
    "\n",
    "#   col1  col2  col3 col4\n",
    "# 4    D     7     2    e\n",
    "# 5    C     4     3    F\n",
    "# 2    B     9     9    c\n",
    "# 0    A     2     0    a\n",
    "# 1    A     1     1    B\n",
    "# 3  NaN     8     4    D\n",
    "\n",
    "# Putting NAs first\n",
    "\n",
    "df.sort_values(by='col1', ascending=False, na_position='first')\n",
    "\n",
    "#   col1  col2  col3 col4\n",
    "# 3  NaN     8     4    D\n",
    "# 4    D     7     2    e\n",
    "# 5    C     4     3    F\n",
    "# 2    B     9     9    c\n",
    "# 0    A     2     0    a\n",
    "# 1    A     1     1    B\n",
    "\n",
    "# Sorting with a key function\n",
    "\n",
    "df.sort_values(by='col4', key=lambda col: col.str.lower())\n",
    "\n",
    "#    col1  col2  col3 col4\n",
    "# 0    A     2     0    a\n",
    "# 1    A     1     1    B\n",
    "# 2    B     9     9    c\n",
    "# 3  NaN     8     4    D\n",
    "# 4    D     7     2    e\n",
    "# 5    C     4     3    F\n",
    "\n",
    "# Natural sort with the key argument, using the natsort <https://github.com/SethMMorton/natsort> package.\n",
    "\n",
    "df = pd.DataFrame({\n",
    "   \"time\": ['0hr', '128hr', '72hr', '48hr', '96hr'],\n",
    "   \"value\": [10, 20, 30, 40, 50]\n",
    "})\n",
    "df\n",
    "#     time  value\n",
    "# 0    0hr     10\n",
    "# 1  128hr     20\n",
    "# 2   72hr     30\n",
    "# 3   48hr     40\n",
    "# 4   96hr     50\n",
    "\n",
    "from natsort import index_natsorted\n",
    "\n",
    "df.sort_values(\n",
    "   by=\"time\",\n",
    "   key=lambda x: np.argsort(index_natsorted(df[\"time\"]))\n",
    ")\n",
    "\n",
    "#     time  value\n",
    "# 0    0hr     10\n",
    "# 3   48hr     40\n",
    "# 2   72hr     30\n",
    "# 4   96hr     50\n",
    "# 1  128hr     20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for setting, values, you need to use df['column'] = ....\n",
    "# you cant use df.column \n",
    "\n",
    "# once this is done , you can refer to that column in the future with df.column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to add element in Python to the end of list using list.insert?\n",
    "\n",
    "# You'll have to pass the new ordinal position to insert using len in this case:\n",
    "\n",
    "a=[1,2,3,4]\n",
    "a.insert(len(a),5)\n",
    "a\n",
    "# [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to write a list to a file in Python\n",
    "# Writing a list to file saves the data contained in a list to a text file.\n",
    "# Each element from the list is written as a single line in the file.\n",
    "\n",
    "# USE file.write() TO WRITE A LIST TO A FILE\n",
    "# Call open(file, mode) with \"w\" as mode to open file for writing. \n",
    "# Use a for-loop to iterate over each element in a list. \n",
    "# Call file.write(data) with each element and a newline character as data to write it to file.\n",
    "\n",
    "a_list = [\"abc\", \"def\", \"ghi\"]\n",
    "textfile = open(\"path\\\\a_file.txt\", \"w\")\n",
    "for element in a_list:\n",
    "    textfile.write(element + \"\\n\")\n",
    "textfile.close()\n",
    "\n",
    "# A_FILE.TXT\n",
    "# abc\n",
    "# def\n",
    "# ghi\n",
    "\n",
    "# or\n",
    "\n",
    "with open(\"path\\\\a_file.txt\", \"w\") as file:\n",
    "\n",
    "    file_lines = \"\\n\".join(a_list)\n",
    "    file.write(file_lines)\n",
    "\n",
    "\n",
    "\n",
    "# OTHER SOLUTIONS\n",
    "# Use pickle to write a list to a file\n",
    "\n",
    "# If the text file is only being saved for use later in the program, this method is more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to write a file to a list in Python\n",
    "\n",
    "# SAMPLE1.TXT\n",
    "# a\n",
    "# b\n",
    "# c\n",
    "# d\n",
    "# e\n",
    "\n",
    "file = open(\"sample1.txt\", \"r\")\n",
    "file_lines = file.read()\n",
    "list_of_lines = file_lines.split(\"\\n\")\n",
    "\n",
    "print(list_of_lines)\n",
    "# OUTPUT\n",
    "# ['a', 'b', 'c', 'd', 'e']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>style</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yum Yum</td>\n",
       "      <td>cup</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Indomie</td>\n",
       "      <td>cup</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indomie</td>\n",
       "      <td>pack</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     brand style  rating\n",
       "1  Yum Yum   cup     4.0\n",
       "2  Indomie   cup     3.5\n",
       "4  Indomie  pack     5.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'],\n",
    "    'style': ['cup', 'cup', 'cup', 'pack', 'pack'],\n",
    "    'rating': [4, 4, 3.5, 15, 5]\n",
    "})\n",
    "\n",
    "df\n",
    "#     brand style  rating\n",
    "# 0  Yum Yum   cup     4.0\n",
    "# 1  Yum Yum   cup     4.0\n",
    "# 2  Indomie   cup     3.5\n",
    "# 3  Indomie  pack    15.0\n",
    "# 4  Indomie  pack     5.0\n",
    "\n",
    "# By default, it removes duplicate rows based on all columns.\n",
    "\n",
    "df.drop_duplicates()\n",
    "\n",
    "#     brand style  rating\n",
    "# 0  Yum Yum   cup     4.0\n",
    "# 2  Indomie   cup     3.5\n",
    "# 3  Indomie  pack    15.0\n",
    "# 4  Indomie  pack     5.0\n",
    "\n",
    "# To remove duplicates on specific column(s), use subset.\n",
    "\n",
    "df.drop_duplicates(subset=['brand'])\n",
    "\n",
    "#     brand style  rating\n",
    "# 0  Yum Yum   cup     4.0\n",
    "# 2  Indomie   cup     3.5\n",
    "\n",
    "# To remove duplicates and keep last occurrences, use keep.\n",
    "\n",
    "df.drop_duplicates(subset=['brand', 'style'], keep='last')\n",
    "\n",
    "#     brand style  rating\n",
    "# 1  Yum Yum   cup     4.0\n",
    "# 2  Indomie   cup     3.5\n",
    "# 4  Indomie  pack     5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['2015-10-31', '2015-12-02', '2016-01-03', '2016-02-08', '2017-05-05',\n",
       "       '2014-02-11'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return Index without NA/NaN values.\n",
    "\n",
    "idx = pd.Index(['2015-10-31', '2015-12-02', None, '2016-01-03',\n",
    "                '2016-02-08', '2017-05-05', None, '2014-02-11'])\n",
    "  \n",
    "idx.dropna(how='any')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customizing Matplotlib with style sheets and rcParams\n",
    "import matplotlib as mpl\n",
    "from cycler import cycler\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [12, 7]\n",
    "\n",
    "mpl.rcParams['lines.linewidth'] = 2\n",
    "mpl.rcParams['lines.linestyle'] = '--'\n",
    "\n",
    "mpl.rcParams['axes.prop_cycle'] = cycler(color=['r', 'g', 'b', 'y'])\n",
    "plt.plot(data)  # first color is red\n",
    "\n",
    "mpl.rc('lines', linewidth=4, linestyle='-.')\n",
    "\n",
    "plt.rc('font', size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     4.0\n",
       "1     4.0\n",
       "2     3.5\n",
       "3    15.0\n",
       "4     5.0\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'],\n",
    "    'style': ['cup', 'cup', 'cup', 'pack', 'pack'],\n",
    "    'rating': [4, 4, 3.5, 15, 5]\n",
    "})\n",
    "\n",
    "# add a column to df contains rows numbers of df \n",
    "df['row_number'] = range(df.shape[0])\n",
    "\n",
    "# shrink df to 2 columns only\n",
    "df1 = df.loc[:, ['brand', 'style']]\n",
    "\n",
    "# shrink df to 1 column only AKA series\n",
    "df2 = df.loc[:, 'rating']\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2000-01-08 00:00:00', freq='D')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# heiken ashi\n",
    "# Now, let’s calculate Heikin Ashi candles according to the original formula. \n",
    "# Since we need to check the previous candle, we have to skip the first row.\n",
    "# We’ll store the result in a new data frame called df_ha. \n",
    "# We copy the original data of the candles in order to keep the same highs and lows. \n",
    "# Then, we remove the first line.\n",
    "\n",
    "dates = pd.date_range('1/1/2000', periods=8)\n",
    "\n",
    "df = pd.DataFrame(np.random.rand(8,4), index=dates, columns=['Open', 'High', 'Low', 'Close'])\n",
    "\n",
    "df_ha = df.copy()\n",
    "\n",
    "for i in range(df_ha.shape[0]):\n",
    "  if i > 0:\n",
    "    df_ha.loc[df_ha.index[i],'Open'] = (df['Open'][i-1] + df['Close'][i-1])/2\n",
    "  \n",
    "    df_ha.loc[df_ha.index[i],'Close'] = (df['Open'][i] + df['Close'][i] + df['Low'][i] +  df['High'][i])/4\n",
    "\n",
    "df_ha = df_ha.iloc[1:,:]\n",
    "\n",
    "\n",
    "############\n",
    "# TIP\n",
    "\n",
    "# explicit index is:\n",
    "df_ha.index\n",
    "# DatetimeIndex(['2000-01-02', '2000-01-03', '2000-01-04', '2000-01-05',\n",
    "#                '2000-01-06', '2000-01-07', '2000-01-08'],\n",
    "#               dtype='datetime64[ns]', freq='D')\n",
    "\n",
    "# implicit index is:\n",
    "df_ha.shape[0]\n",
    "# from 0 to 7-1=6\n",
    "\n",
    "# put implicit index in df.index method and you get the explicit index\n",
    "df_ha.index[6]\n",
    "# Timestamp('2000-01-08 00:00:00', freq='D')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_afc04_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Images</th>\n",
       "      <th class=\"col_heading level0 col1\" >location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_afc04_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_afc04_row0_col0\" class=\"data row0 col0\" >img1</td>\n",
       "      <td id=\"T_afc04_row0_col1\" class=\"data row0 col1\" ><a href=\"New/gfg.png\">gfg.png</a></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afc04_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_afc04_row1_col0\" class=\"data row1 col0\" >img2</td>\n",
       "      <td id=\"T_afc04_row1_col1\" class=\"data row1 col1\" ><a href=\"New/1.png\">1.png</a></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afc04_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_afc04_row2_col0\" class=\"data row2 col0\" >img3</td>\n",
       "      <td id=\"T_afc04_row2_col1\" class=\"data row2 col1\" ><a href=\"New/gfg2.png\">gfg2.png</a></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afc04_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_afc04_row3_col0\" class=\"data row3 col0\" >img4</td>\n",
       "      <td id=\"T_afc04_row3_col1\" class=\"data row3 col1\" ><a href=\"New/oled.png\">oled.png</a></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afc04_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_afc04_row4_col0\" class=\"data row4 col0\" >img5</td>\n",
       "      <td id=\"T_afc04_row4_col1\" class=\"data row4 col1\" ><a href=\"New/oled2.png\">oled2.png</a></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1caf8410250>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to create a table with clickable hyperlink to a local file in Pandas\n",
    "\n",
    "# # Step 2 : Creating dataset of local path images\n",
    "dataset = [dict(Images='img1', location=r'New/gfg.png'),\n",
    "           dict(Images='img2', location=r'New/1.png'),\n",
    "           dict(Images='img3', location=r'New/gfg2.png'),\n",
    "           dict(Images='img4', location=r'New/oled.png'),\n",
    "           dict(Images='img5', location=r'New/oled2.png')]\n",
    "  \n",
    "df = pd.DataFrame(dataset)\n",
    "  \n",
    "# # Function to convert file path into clickable form.\n",
    "  \n",
    "def fun(path):\n",
    "    \n",
    "    # basename returns the final component of a path\n",
    "    # c:/folder/file.jpg ---> file.jpg\n",
    "    f_url = os.path.basename(path)\n",
    "      \n",
    "    # convert the path into clickable link\n",
    "    return '<a href=\"{}\">{}</a>'.format(path, f_url)\n",
    "  \n",
    "  \n",
    "# # applying function \"fun\" on column \"location\".\n",
    "df = df.style.format({'location': fun})\n",
    "  \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(dict(age=[5, 6, np.NaN],born=[pd.NaT, pd.Timestamp('1939-05-27'),pd.Timestamp('1940-04-25')],\n",
    "#                    name=['Alfred', 'Batman', ''],toy=[None, 'Batmobile', 'Joker']))\n",
    "\n",
    "# df\n",
    "#    age       born    name        toy\n",
    "# 0  5.0        NaT  Alfred       None\n",
    "# 1  6.0 1939-05-27  Batman  Batmobile\n",
    "# 2  NaN 1940-04-25              Joker\n",
    "\n",
    "# df.isna()\n",
    "#      age   born   name    toy\n",
    "# 0  False   True  False   True\n",
    "# 1  False  False  False  False\n",
    "# 2   True  False  False  False\n",
    "\n",
    "# Show which entries in a Series are NA.\n",
    "\n",
    "# ser = pd.Series([5, 6, np.NaN])\n",
    "# ser\n",
    "# 0    5.0\n",
    "# 1    6.0\n",
    "# 2    NaN\n",
    "# dtype: float64\n",
    "\n",
    "# ser.isna()\n",
    "# 0    False\n",
    "# 1    False\n",
    "# 2     True\n",
    "# dtype: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n",
    "#                    [3, 4, np.nan, 1],\n",
    "#                    [np.nan, np.nan, np.nan, np.nan],\n",
    "#                    [np.nan, 3, np.nan, 4]],\n",
    "#                    columns=list(\"ABCD\"))\n",
    "\n",
    "# df\n",
    "#      A    B   C    D\n",
    "# 0  NaN  2.0 NaN  0.0\n",
    "# 1  3.0  4.0 NaN  1.0\n",
    "# 2  NaN  NaN NaN  NaN\n",
    "# 3  NaN  3.0 NaN  4.0\n",
    "\n",
    "# Replace all NaN elements with 0s.\n",
    "\n",
    "# df.fillna(0)\n",
    "#      A    B    C    D\n",
    "# 0  0.0  2.0  0.0  0.0\n",
    "# 1  3.0  4.0  0.0  1.0\n",
    "# 2  0.0  0.0  0.0  0.0\n",
    "# 3  0.0  3.0  0.0  4.0\n",
    "\n",
    "# We can also propagate non-null values forward or backward.\n",
    "\n",
    "# df.fillna(method=\"ffill\")\n",
    "#      A    B   C    D\n",
    "# 0  NaN  2.0 NaN  0.0\n",
    "# 1  3.0  4.0 NaN  1.0\n",
    "# 2  3.0  4.0 NaN  1.0\n",
    "# 3  3.0  3.0 NaN  4.0\n",
    "\n",
    "# demo = pd.Series(range(6))\n",
    "# demo.loc[2:4] = np.nan\n",
    "# demo\n",
    "\n",
    "# 0    0.0\n",
    "# 1    1.0\n",
    "# 2    NaN\n",
    "# 3    NaN\n",
    "# 4    NaN\n",
    "# 5    5.0\n",
    "\n",
    "# # Forward-Fill\n",
    "# demo.fillna(method='ffill')\n",
    "\n",
    "# 0    0.0\n",
    "# 1    1.0\n",
    "# 2    1.0\n",
    "# 3    1.0\n",
    "# 4    1.0\n",
    "# 5    5.0\n",
    "\n",
    "# # Backward-Fill\n",
    "# demo.fillna(method='bfill')\n",
    "\n",
    "# 0    0.0\n",
    "# 1    1.0\n",
    "# 2    5.0\n",
    "# 3    5.0\n",
    "# 4    5.0\n",
    "# 5    5.0\n",
    "\n",
    "# Replace all NaN elements in column ‘A’, ‘B’, ‘C’, and ‘D’, with 0, 1, 2, and 3 respectively.\n",
    "\n",
    "# values = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3}\n",
    "# df.fillna(value=values)\n",
    "\n",
    "#      A    B    C    D\n",
    "# 0  0.0  2.0  2.0  0.0\n",
    "# 1  3.0  4.0  2.0  1.0\n",
    "# 2  0.0  1.0  2.0  3.0\n",
    "# 3  0.0  3.0  2.0  4.0\n",
    "\n",
    "# Only replace the first NaN element.\n",
    "\n",
    "# df.fillna(value=values, limit=1)\n",
    "#      A    B    C    D\n",
    "# 0  0.0  2.0  2.0  0.0\n",
    "# 1  3.0  4.0  NaN  1.0\n",
    "# 2  NaN  1.0  NaN  3.0\n",
    "# 3  NaN  3.0  NaN  4.0\n",
    "\n",
    "# When filling using a DataFrame, replacement happens along the same column names and same indices\n",
    "\n",
    "# df2 = pd.DataFrame(np.zeros((4, 4)), columns=list(\"ABCE\"))\n",
    "# df.fillna(df2)\n",
    "\n",
    "#      A    B    C    D\n",
    "# 0  0.0  2.0  0.0  0.0\n",
    "# 1  3.0  4.0  0.0  1.0\n",
    "# 2  0.0  0.0  0.0  NaN\n",
    "# 3  0.0  3.0  0.0  4.0\n",
    "# Note that column D is not affected since it is not present in df2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using break\n",
    "# The break statement will completely break out of the current loop,\n",
    "# meaning it won’t run any more of the statements contained inside of it\n",
    "\n",
    "# >>> names = [\"Rose\", \"Max\", \"Nina\", \"Phillip\"]\n",
    "# >>> for name in names:\n",
    "# ...     print(f\"Hello, {name}\")\n",
    "# ...     if name == \"Nina\":\n",
    "# ...         break\n",
    "# ...\n",
    "# Hello, Rose\n",
    "# Hello, Max\n",
    "# Hello, Nina\n",
    "# break completely breaks out of the loop.\n",
    "\n",
    "# Using continue\n",
    "# continue works a little differently. Instead, it goes back to the start of the loop, skipping over any other statements contained within the loop.\n",
    "\n",
    "# >>> for name in names:\n",
    "# ...     if name != \"Nina\":\n",
    "# ...         continue\n",
    "# ...     print(f\"Hello, {name}\")\n",
    "# ...\n",
    "# Hello, Nina\n",
    "# continue continues to the start of the loop\n",
    "\n",
    "# break and continue visualized\n",
    "# What happens when we run the code from this Python file?\n",
    "\n",
    "# # Python file names.py\n",
    "# names = [\"Jimmy\", \"Rose\", \"Max\", \"Nina\", \"Phillip\"]\n",
    "\n",
    "# for name in names:\n",
    "#     if len(name) != 4:\n",
    "#         continue\n",
    "\n",
    "#     print(f\"Hello, {name}\")\n",
    "\n",
    "#     if name == \"Nina\":\n",
    "#         break\n",
    "\n",
    "# print(\"Done!\")\n",
    "\n",
    "# Results\n",
    "#  See if you can guess the results before expanding this section.\n",
    "# (env) $ python names.py\n",
    "\n",
    "# Hello, Rose\n",
    "# Hello, Nina\n",
    "# Done!\n",
    "# Using break and continue in nested loops.\n",
    "# Remember, break and continue only work for the current loop. Even though I’ve been programming Python for years, this is something that still trips me up!\n",
    "\n",
    "# >>> names = [\"Rose\", \"Max\", \"Nina\"]\n",
    "# >>> target_letter = 'x'\n",
    "# >>> for name in names:\n",
    "# ...     print(f\"{name} in outer loop\")\n",
    "# ...     for char in name:\n",
    "# ...             if char == target_letter:\n",
    "# ...                 print(f\"Found {name} with letter: {target_letter}\")\n",
    "# ...                 print(\"breaking out of inner loop\")\n",
    "# ...                 break\n",
    "# ...\n",
    "# Rose in outer loop\n",
    "# Max in outer loop\n",
    "# Found Max with letter: x\n",
    "# breaking out of inner loop\n",
    "# Nina in outer loop\n",
    "# >>>\n",
    "# break in the inner loop only breaks out of the inner loop! The outer loop continues to run.\n",
    "\n",
    "# Loop Control in while loops\n",
    "# You can also use break and continue in while loops. One common scenario is running a loop forever, until a certain condition is met.\n",
    "\n",
    "# >>> count = 0 \n",
    "# >>> while True:\n",
    "# ...     count += 1\n",
    "# ...     if count == 5:\n",
    "# ...             print(\"Count reached\")\n",
    "# ...             break\n",
    "# ...\n",
    "# Count reached\n",
    "# Be careful that your condition will eventually be met, or else your program will get stuck in an infinite loop. For production use, it’s better to use asynchronous programming.\n",
    "\n",
    "# Loops and the return statement\n",
    "# Just like in functions, consider the return statement the hard kill-switch of the loop.\n",
    "\n",
    "# >>> def name_length(names):\n",
    "# ...     for name in names:\n",
    "# ...             print(name)\n",
    "# ...             if name == \"Nina\":\n",
    "# ...                     return \"Found the special name\"\n",
    "# ...\n",
    "# >>> names = [\"Max\", \"Nina\", \"Rose\"]\n",
    "# >>> name_length(names)\n",
    "# Max\n",
    "# Nina\n",
    "# 'Found the special name'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION SCOPE\n",
    "# Scope inside a function\n",
    "# Inside of a function in Python, the scope changes.\n",
    "\n",
    "# Think about it this way: \n",
    "# scoping in Python happens with whitespace. \n",
    "# When we delineate the code a function contains by indenting it under a function definition, \n",
    "# it’s scope changes to a new internal scope. \n",
    "# It has access to the variables defined outside of it, but it can’t change them.\n",
    "\n",
    "# Once the function is done running, its scope goes away, as do its defined variables.\n",
    "\n",
    "# Let’s double check this in the REPL:\n",
    "\n",
    "# >>> def twitter_info():\n",
    "# ...     twitter_account = \"nnja\"\n",
    "# ...     print(f\"Account inside function: {twitter_account}\")\n",
    "# ...\n",
    "# >>> twitter_info()\n",
    "# Account inside function: nnja\n",
    "# >>> print(f\"Account outside of function: {twitter_account}\")\n",
    "\n",
    "# Traceback (most recent call last):\n",
    "#   File \"<stdin>\", line 1, in <module>\n",
    "# NameError: name 'twitter_account' is not defined\n",
    "\n",
    "# We get a NameError when trying to access the twitter_account variable outside of the function. \n",
    "# That’s because it’s out of scope, exactly like we expected it to be.\n",
    "\n",
    "# Using variables defined outside of the function\n",
    "# Generally, we want to be careful when using variables defined outside of our function.\n",
    "\n",
    "# Note, that if we try to change the value of a variable defined outside of our function, \n",
    "# we’ll see the changes in the function, but not outside of it.\n",
    "\n",
    "# You can’t change variables defined outside of the function inside of the function. \n",
    "# If you try to, your changes will only apply while the function is running. \n",
    "# Once the function is done running, the value goes back to what it was before your function ran.\n",
    "\n",
    "# A little confusing, but let’s see it in action:\n",
    "\n",
    "# >>> name = \"Nina\"\n",
    "# >>> print(f\"Name outside of function: {name}\")\n",
    "# Name outside of function: Nina\n",
    "# >>>\n",
    "# >>> def try_change_name():\n",
    "# ...     name = \"Max\"\n",
    "# ...     print(f\"Name inside of function: {name}\")\n",
    "# ...\n",
    "# >>> try_change_name()\n",
    "# Name inside of function: Max\n",
    "# >>> print(f\"Name outside of function: {name}\")\n",
    "# Name outside of function: Nina\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments Danger Zone\n",
    "# Never use mutable types, like lists as a default argument.\n",
    "\n",
    "# We’ll talk more about lists and mutability in the coming chapter, but for the time being remember to never use an empty list as a default value to a function.\n",
    "\n",
    "# Why? Because it won’t work like you’d expect it to.\n",
    "\n",
    "# >>> # Don't do this!\n",
    "# >>> def add_five_to_list(my_list=[]):\n",
    "# ...     my_list.append(5)\n",
    "# ...     return my_list\n",
    "# ...\n",
    "# >>> # This works like we expected it to.\n",
    "# >>> add_five_to_list()\n",
    "# [5]\n",
    "# >>> # Huh?\n",
    "# >>> add_five_to_list()\n",
    "# [5, 5]\n",
    "# >>> # We see that the original `my_list` is still being modified.\n",
    "# >>> add_five_to_list()\n",
    "# [5, 5, 5]\n",
    "# If you need to use a mutable type, like a list as a default, use a marker instead. We’ll cover this technique when we talk about lists in the next chapter.\n",
    "\n",
    "# In Python, default arguments are evaluated only once – when the function is defined. Not each time the function is called. That means if you use a value that can be changed, it won’t behave like you’d expect it to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas.DataFrame.drop\n",
    "\n",
    "\n",
    "# df = pd.DataFrame({\"name\": ['Alfred', 'Batman', 'Catwoman'],\n",
    "#                    \"toy\": [np.nan, 'Batmobile', 'Bullwhip'],\n",
    "#                    \"born\": [pd.NaT, pd.Timestamp(\"1940-04-25\"),pd.NaT]})\n",
    "# df\n",
    "#        name        toy       born\n",
    "# 0    Alfred        NaN        NaT\n",
    "# 1    Batman  Batmobile 1940-04-25\n",
    "# 2  Catwoman   Bullwhip        NaT\n",
    "\n",
    "# Drop the rows where at least one element is missing.\n",
    "\n",
    "# df.dropna()\n",
    "#      name        toy       born\n",
    "# 1  Batman  Batmobile 1940-04-25\n",
    "\n",
    "# Drop the columns where at least one element is missing.\n",
    "\n",
    "# df.dropna(axis='columns')\n",
    "#        name\n",
    "# 0    Alfred\n",
    "# 1    Batman\n",
    "# 2  Catwoman\n",
    "\n",
    "# Drop the rows where all elements are missing.\n",
    "\n",
    "# df.dropna(how='all')\n",
    "#        name        toy       born\n",
    "# 0    Alfred        NaN        NaT\n",
    "# 1    Batman  Batmobile 1940-04-25\n",
    "# 2  Catwoman   Bullwhip        NaT\n",
    "\n",
    "# Keep only the rows with at least 2 non-NA values.\n",
    "\n",
    "# df.dropna(thresh=2)\n",
    "#        name        toy       born\n",
    "# 1    Batman  Batmobile 1940-04-25\n",
    "# 2  Catwoman   Bullwhip        NaT\n",
    "\n",
    "# Define in which columns to look for missing values.\n",
    "\n",
    "# df.dropna(subset=['name', 'toy'])\n",
    "#        name        toy       born\n",
    "# 1    Batman  Batmobile 1940-04-25\n",
    "# 2  Catwoman   Bullwhip        NaT\n",
    "\n",
    "# Keep the DataFrame with valid entries in the same variable.\n",
    "\n",
    "# df.dropna(inplace=True)\n",
    "# df\n",
    "#      name        toy       born\n",
    "# 1  Batman  Batmobile 1940-04-25\n",
    "\n",
    "# Remove rows or columns by specifying label names and corresponding axis,\n",
    "# or by specifying directly index or column names.\n",
    "\n",
    "\n",
    "# df = pd.DataFrame(np.arange(12).reshape(3, 4),\n",
    "#                   columns=['A', 'B', 'C', 'D'])\n",
    "# df\n",
    "#    A  B   C   D\n",
    "# 0  0  1   2   3\n",
    "# 1  4  5   6   7\n",
    "# 2  8  9  10  11\n",
    "\n",
    "# Drop columns\n",
    "\n",
    "# df.drop(['B', 'C'], axis=1)\n",
    "#    A   D\n",
    "# 0  0   3\n",
    "# 1  4   7\n",
    "# 2  8  11\n",
    "\n",
    "# df.drop(columns=['B', 'C'])\n",
    "#    A   D\n",
    "# 0  0   3\n",
    "# 1  4   7\n",
    "# 2  8  11\n",
    "\n",
    "# Drop a row by index\n",
    "\n",
    "# df.drop([0, 1])\n",
    "#    A  B   C   D\n",
    "# 2  8  9  10  11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove a directory with its subfolders\n",
    "\n",
    "# if os.path.exists(outdir):\n",
    "#     shutil.rmtree(outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nice way to automaticly update csv\n",
    "# note :  df index is a kind of time format\n",
    "\n",
    "# c=pd.to_datetime(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "# b=pd.to_datetime(df.index[-1]) #+pd.to_timedelta(1, unit=\"d\")\n",
    "# if (c- b) < pd.to_timedelta(1, unit=\"d\"):\n",
    "#     print(c-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to find the dfs that are lagging behind in terms of last date \n",
    "# put last date of all dfs in a dict \n",
    "# than remove the ones that are diffrent than the majority\n",
    "# for example youll find \n",
    "# 200 entries are the same date\n",
    "# 23 diffrent dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install talib \n",
    "\n",
    "#  googel colab\n",
    "\n",
    "# !wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz\n",
    "# !tar xvzf ta-lib-0.4.0-src.tar.gz\n",
    "# import os\n",
    "# os.chdir('ta-lib') # Can't use !cd in co-lab\n",
    "# !./configure --prefix=/usr\n",
    "# !make\n",
    "# !make install\n",
    "# os.chdir('../')\n",
    "# !pip install TA-Lib\n",
    "\n",
    "\n",
    "# on windows \n",
    "\n",
    "# downlooad ta-lib-0.4.0-msvc and put it it c:\\talib\n",
    "# add it to path\n",
    "\n",
    "# Download package from here: https://www.lfd.uci.edu/~gohlke/pythonlibs/#ta-lib . \n",
    "\n",
    "#in terminal with virenv open\n",
    "# Cd to the downloaded file's dir\n",
    "# pip install TA_Lib‑0.4.19‑cp37‑cp37m‑win_amd64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# share variables between two jupyter notebooks:\n",
    "\n",
    "# jupyter notbook1:\n",
    "# var1\n",
    "# %store var1\n",
    "\n",
    "# jupyter notbook2:\n",
    "# %store -r var1\n",
    "# var1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# to make subfolders\n",
    "# os.makedirs\n",
    "\n",
    "# to make only one folder\n",
    "# os.mkdir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime.now().strftime('%Y-%m-%d_%H-%M-%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data['Time'] = pd.to_datetime(data['Time'], unit='ms')\n",
    "# data.set_index('Time', inplace=True)\n",
    "# data.to_csv(fullname) \n",
    "\n",
    "# tem_data = pd.read_csv(fullname, index_col='Time')\n",
    "# d = tem_data.index[-1] - datetime.now()\n",
    "\n",
    "# TypeError: unsupported operand type(s) for -: 'str' and 'datetime.datetime'\n",
    "\n",
    "# looks like when i save df as csv datetime turned into an str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ccxt gives the last candle which has not closed yet\n",
    "# so use [:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# argrelextrema takes np array only not list\n",
    "l=np.array([1,2,3,4,5,6,7,6,5,4,3,2,3,4,5,6,7,8,9,10,11,12,13,12])\n",
    "# use [0] at the end because argrel returns a tuple with two elements\n",
    "co = argrelextrema(l, np.greater, order=1)[0]\n",
    "co\n",
    "# array([ 6, 22], dtype=int64)\n",
    "# 6 and 22 are indexs coresspend to 7 and 13\n",
    "\n",
    "\n",
    "l=np.array([1,2,3,4,5,6,7,6,5,4,3,2,3,4,5,6,7,8,9,10,11,12,13])\n",
    "co = argrelextrema(l, np.greater, order=1)[0]\n",
    "co\n",
    "# array([6], dtype=int64)\n",
    "\n",
    "# after removing the last digit \"12\" we find that argrelextream coudnot regonize\n",
    "# the peak at '13' simply because it needs confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zoom plot without problem by using svg format\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading date columns from a CSV file\n",
    "# By default, date columns are represented as object when loading data from a CSV file.\n",
    "\n",
    "# For example, data_1.csv\n",
    "# date,product,price\n",
    "# 1/1/2019,A,10\n",
    "# 1/2/2020,B,20\n",
    "# 1/3/1998,C,30\n",
    "# The date column gets read as an object data type using the default read_csv():\n",
    "\n",
    "# df = pd.read_csv('data/data_1.csv')\n",
    "# df.info()\n",
    "\n",
    "# RangeIndex: 3 entries, 0 to 2\n",
    "# Data columns (total 3 columns):\n",
    "#  #   Column   Non-Null Count  Dtype \n",
    "# ---  ------   --------------  ----- \n",
    "#  0   date     3 non-null      object\n",
    "#  1   product  3 non-null      object\n",
    "#  2   price    3 non-null      int64 \n",
    "# dtypes: int64(1), object(2)\n",
    "# memory usage: 200.0+ bytes\n",
    "\n",
    "# To read the date column correctly, we can use the argument parse_dates to specify a list of date columns.\n",
    "\n",
    "# df = pd.read_csv('data/data_3.csv', parse_dates=['date'])\n",
    "# df.info()\n",
    "\n",
    "# RangeIndex: 3 entries, 0 to 2\n",
    "# Data columns (total 3 columns):\n",
    "#  #   Column   Non-Null Count  Dtype         \n",
    "# ---  ------   --------------  -----         \n",
    "#  0   date     3 non-null      datetime64[ns]\n",
    "#  1   product  3 non-null      object        \n",
    "#  2   price    3 non-null      int64         \n",
    "# dtypes: datetime64[ns](1), int64(1), object(1)\n",
    "# memory usage: 200.0+ bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df1=pd.read_csv(\"C:\\\\Users\\\\Grant\\\\Desktop\\\\work_git\\\\work\\data\\\\4h\\\\1INCHUSDT_4h.csv\",index_col=['Time'], parse_dates=['Time'])\n",
    "\n",
    "df2=pd.read_csv(\"C:\\\\Users\\\\Grant\\\\Desktop\\\\work_git\\\\work\\data\\\\4h\\\\1INCHUSDT_4h.csv\",index_col=0, parse_dates=['Time'])\n",
    "\n",
    "df3=pd.read_csv(\"C:\\\\Users\\\\Grant\\\\Desktop\\\\work_git\\\\work\\data\\\\4h\\\\1INCHUSDT_4h.csv\", parse_dates=True)\n",
    "\n",
    "df3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "apple_df = pd.read_csv(\"C:\\\\Users\\\\Grant\\\\Desktop\\\\work_git\\\\work\\data\\\\4h\\\\1INCHUSDT_4h.csv\" , index_col=0, parse_dates=True)\n",
    "dt_range = pd.date_range(start='2022-01-01', end='2022-03-31')\n",
    "apple_df_m = apple_df[apple_df.index.isin(dt_range)]\n",
    "# apple_df_m.head()\n",
    "apple_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date2num\n",
    "\n",
    "# Convert datetime objects to Matplotlib dates.\n",
    "\n",
    "# num2date\n",
    "\n",
    "# Convert Matplotlib dates to datetime objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas.DataFrame.shape\n",
    "\n",
    "# Return a tuple representing the dimensionality of the DataFrame.\n",
    "\n",
    "df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
    "df.shape\n",
    "# (2, 2)\n",
    "\n",
    "df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4], 'col3': [5, 6]})\n",
    "df.shape\n",
    "# (2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot two chart on top of each other with plotly\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "# Create and style traces\n",
    "fig.add_trace(go.Scatter(x=data['Time'], y=data['SMA']))\n",
    "fig.add_trace(go.Scatter(x=data['Time'], y=data['Close']))\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when defining a default argument to funtion \n",
    "# you may encounter old data been used\n",
    "\n",
    "# def fun(df=data):\n",
    "\n",
    "# it better to do \n",
    "# def fun(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find cell in df by its index\n",
    "\n",
    "# df['close'][index]\n",
    "# if index is numbers :\n",
    "# df['close'][2]\n",
    "\n",
    "# if index is in time format : \n",
    "# df['close'][\"2021-01-23\"]\n",
    "\n",
    "# if index is a letter:\n",
    "# df['close'][\"c\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True</th>\n",
       "      <th>False</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   True  False\n",
       "0     1      3\n",
       "1     2      4\n",
       "2     3      5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pandas Series - Why use loc\n",
    "\n",
    "# Explicit is better than implicit.\n",
    "\n",
    "# df[boolean_mask] selects rows where boolean_mask is True, \n",
    "# but there is a corner case when you might not want it to: \n",
    "# when df has boolean-valued column labels:\n",
    "\n",
    "df = pd.DataFrame({True:[1,2,3],False:[3,4,5]})\n",
    "df\n",
    "\n",
    "#    False  True \n",
    "# 0      3      1\n",
    "# 1      4      2\n",
    "# 2      5      3\n",
    "\n",
    "# You might want to use df[[True]] to select the True column. \n",
    "# Instead it raises a ValueError:\n",
    "\n",
    "# df[[True]]\n",
    "# ValueError: Item wrong length 1 instead of 3.\n",
    "\n",
    "# Versus using loc:\n",
    "\n",
    "# df.loc[[True]]\n",
    "\n",
    "#    False  True \n",
    "# 0      3      1\n",
    "\n",
    "# In contrast, the following does not raise ValueError \n",
    "# even though the structure of df2 is almost the same as df1 above:\n",
    "\n",
    "# df2 = pd.DataFrame({'A':[1,2,3],'B':[3,4,5]})\n",
    "# df2\n",
    "\n",
    "#    A  B\n",
    "# 0  1  3\n",
    "# 1  2  4\n",
    "# 2  3  5\n",
    "\n",
    "# df2[['B']]\n",
    "\n",
    "#    B\n",
    "# 0  3\n",
    "# 1  4\n",
    "# 2  5\n",
    "\n",
    "# Thus, df[boolean_mask] does not always behave the same as df.loc[boolean_mask]. \n",
    "# Even though this is arguably an unlikely use case, \n",
    "# I would recommend always using df.loc[boolean_mask] instead of df[boolean_mask] \n",
    "# because the meaning of df.loc's syntax is explicit. \n",
    "# With df.loc[indexer] you know automatically that df.loc is selecting rows. \n",
    "# In contrast, it is not clear if df[indexer] will select rows or columns (or raise ValueError) \n",
    "# without knowing details about indexer and df.\n",
    "\n",
    "# df.loc[row_indexer, column_index] can select rows and columns. \n",
    "# df[indexer] can only select rows or columns \n",
    "# depending on the type of values in indexer and the type of column values df has (again, are they boolean?).\n",
    "\n",
    "# df2.loc[[True,False,True], 'B']\n",
    " \n",
    "# 0    3\n",
    "# 2    5\n",
    "# Name: B, dtype: int64\n",
    "\n",
    "# When a slice is passed to df.loc the end-points are included in the range. \n",
    "# When a slice is passed to df[...], the slice is interpreted as a half-open interval:\n",
    "\n",
    "# df2.loc[1:2]\n",
    "\n",
    "#    A  B\n",
    "# 1  2  4\n",
    "# 2  3  5\n",
    "\n",
    "# df2[1:2]\n",
    " \n",
    "#    A  B\n",
    "# 1  2  4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a list into df with specific index \n",
    "\n",
    "\n",
    "def isSupport(df,i):\n",
    "  # fractal (i-2)>(i-1)>i<(i+1)<(i+2)\n",
    "  support = df['Low'][i] < df['Low'][i-1]  and df['Low'][i] < df['Low'][i+1] \\\n",
    "  and df['Low'][i+1] < df['Low'][i+2] and df['Low'][i-1] < df['Low'][i-2]\n",
    "\n",
    "  return support\n",
    "\n",
    "def isResistance(df,i):\n",
    "  resistance = df['High'][i] > df['High'][i-1]  and df['High'][i] > df['High'][i+1] \\\n",
    "  and df['High'][i+1] > df['High'][i+2] and df['High'][i-1] > df['High'][i-2] \n",
    "\n",
    "  return resistance\n",
    "\n",
    "  pair = \"xrp\".upper()\n",
    "data=pd.read_csv(f\"C:\\\\Users\\Grant\\Desktop\\work_git\\work\\data\\\\4h\\{pair}USDT_4h.csv\", parse_dates=True)\n",
    "# data=pd.read_csv(\"C:\\\\Users\\Grant\\Desktop\\work_git\\work\\data\\\\1d\\ENSUSDT_1d.csv\", parse_dates=True)\n",
    "# data[-55:]\n",
    "\n",
    "levels = []\n",
    "  # start from 2 because i need i-2\n",
    "  # end at shape[0]-2 because  i need i+2\n",
    "  # i is the number of current row\n",
    "for i in range(2,data.shape[0]-2):\n",
    "    if isSupport(data,i):\n",
    "        levels.append((i,data['Low'][i]))\n",
    "        \n",
    "    elif isResistance(data,i):\n",
    "        levels.append((i,data['High'][i]))\n",
    "\n",
    "\n",
    "for i in levels:\n",
    "  rowIndex = data.index[i[0]]\n",
    "  data.loc[rowIndex, 'levels'] = i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when using jupytr beaware of mixing variable with othr dataframes like if you have the variable of df1\n",
    "# and try to plot df2 with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember that data is in UTC but my time is UTC+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in functions must use timeframe=timeframe and limit=Limit \n",
    "\n",
    "# or the default take over and alot of problems arise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df is empty\n",
    "\n",
    "# if (df):\n",
    "#     print('hh')\n",
    "# else:\n",
    "#     print('else')\n",
    "\n",
    "\n",
    "# ValueError: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
    "\n",
    "# solution\n",
    "\n",
    "# if len(df):\n",
    "#     print('hh')\n",
    "# else:\n",
    "#     print('else')\n",
    "\n",
    "\n",
    "\n",
    "# or \n",
    "\n",
    "# if df.empty:\n",
    "#     print('hh')\n",
    "# else:\n",
    "#     print('else')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# virtual env\n",
    "# PS C:\\Users\\Grant\\virenv> py -m venv algo\n",
    "# PS C:\\Users\\Grant\\virenv> cd algo\n",
    "# PS C:\\Users\\Grant\\virenv\\algo> cd Scripts\n",
    "# PS C:\\Users\\Grant\\virenv\\algo\\Scripts> ./activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "# pd.options.display.max_rows\n",
    "# Out[2]: 15\n",
    "\n",
    "# pd.options.display.max_rows = 999\n",
    "\n",
    "# pd.options.display.max_rows\n",
    "# Out[4]: 999\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_loc : Get integer location (implicit index) , slice or boolean mask for requested label.\n",
    "# \n",
    "# search index\n",
    "# data.index.get_loc('2021-07-15 00:00:00')\n",
    "# \n",
    "# search df columns\n",
    "# data.get_loc('value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ISO 8601 Duration strings\n",
    "# pd.Timedelta(\"P0DT0H1M0S\")\n",
    "# Out[13]: Timedelta('0 days 00:01:00')\n",
    "\n",
    "# pd.Timedelta(\"P0DT0H0M0.000000123S\")\n",
    "# Out[14]: Timedelta('0 days 00:00:00.000000123')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index has no iloc\n",
    "\n",
    "# time in df is a numpy time not a python datetime; numpy time is considered as int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# always take a look at the data; because i had a problem with read csv i did not give it index col "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (function) flatnonzero: (a: ArrayLike) -> NDArray[intp]\n",
    "# Return indices that are non-zero in the flattened version of a.\n",
    "\n",
    "# This is equivalent to np.nonzero(np.ravel(a))[0].\n",
    "\n",
    "# Parameters\n",
    "# a : array_like\n",
    "#     Input data.\n",
    "\n",
    "# Returns\n",
    "# res : ndarray\n",
    "#     Output array, containing the indices of the elements of a.ravel() that are non-zero.\n",
    "\n",
    "# See Also\n",
    "# nonzero : Return the indices of the non-zero elements of the input array.\n",
    "# ravel : Return a 1-D array containing the elements of the input array.\n",
    "\n",
    "# Examples\n",
    "# >>> x = np.arange(-2, 3)\n",
    "# >>> x\n",
    "# array([-2, -1,  0,  1,  2])\n",
    "# >>> np.flatnonzero(x)\n",
    "# array([0, 1, 3, 4])\n",
    "# Use the indices of the non-zero elements as an index array to extract these elements:\n",
    "\n",
    "# >>> x.ravel()[np.flatnonzero(x)]\n",
    "# array([-2, -1,  1,  2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if a value exists in pandas dataframe index\n",
    "\n",
    "# 'value' in df.index\n",
    "\n",
    "# g in df.<your selected field>.values\n",
    "# g in df.index.values\n",
    "# I find that adding the \".values\" to get a simple list or ndarray out \n",
    "# makes exist or \"in\" checks run more smoothly with the other python tools.\n",
    "\n",
    "# This was really helpful to point out. I have a hierarchical case \n",
    "# where in g in df.index produces true \n",
    "# and in g in df.index.values false. Interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.codegrepper.com/code-examples/python/second+row+to+last+index+pandas\n",
    "\n",
    "# https://www.codegrepper.com/code-examples/python/pandas+how+to+get+last+index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/61116489/indexes-getting-unordered-when-numbers-are-sorted-in-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.pythontutorial.net/python-basics/python-check-if-file-exists/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://linuxize.com/post/python-get-change-current-working-directory/#:~:text=To%20find%20the%20current%20working,chdir(path)%20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/how-to-export-pandas-dataframe-to-csv-2038e43d9c03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save a webpage as pdf just look for print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     do something\n",
    "# except:\n",
    "#     print('2')\n",
    "#     try:\n",
    "#         print('1')\n",
    "#     except:\n",
    "#         print('0')\n",
    "\n",
    "# the last try execpt loop will not work and will give you no eror\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error\n",
    "# TypeError: '>' not supported between instances of 'NoneType' and 'NoneType'\n",
    "\n",
    "# this error means you are compairng number with nan \n",
    "# in my case i put 1d in the timeframe wich was alot for a new coin because \n",
    "# i was asking for 111 candles\n",
    "# so i change to 1 hr and voila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not a:\n",
    "#   print(\"List is empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in not in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/29700214/get-the-closest-datetime-from-a-list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # any all list comprehension\n",
    "\n",
    "# Python uses list data type to store multiple data in a sequential index. It works like a numeric array of other programming languages. filter() method is a very useful method of Python. One or more data values can be filtered from any string or list or dictionary in Python by using filter() method.  It filters data based on any particular condition. It stores data when the condition returns true and discard data when returns false. How the string data in a list can be filtered in Python is shown in this article by using different examples. You have to use Python 3+ to test the examples of this article.\n",
    "# Filter a list of string using another list\n",
    "# This example shows how the data in a list of string can be filtered without using any method. The list of the string is filtered here by using another list. Here, two list variables are declared with the name list1 and list2. The values of list2 is filtered by using the values of list1. The script will match the first word of each value of list2 with the values of list1 and print those values that don’t exist in list1.\n",
    "\n",
    "# # Declare two list variables\n",
    "# list1 = ['Perl', 'PHP', 'Java', 'ASP']\n",
    "# list2 = ['JavaScript is client-side scripting language',\n",
    "#          'PHP is a server-side scripting language',\n",
    "#          'Java is a programming language',\n",
    "#          'Bash is a scripting language']\n",
    " \n",
    "# # Filter the second list based on first list\n",
    "# filter_data = [x for x in list2 if\n",
    "#               all(y not in x for y in list1)]\n",
    " \n",
    "# # Print list data before filter and after filter\n",
    "# print(\"The content of the first list:\", list1)\n",
    "# print(\"The content of the second list:\", list2)\n",
    "# print(\"The content of the second list after filter:\", filter_data)\n",
    "# Output:\n",
    "\n",
    "# Run the script. Here, list1 does not contain the word ‘Bash’. \n",
    "# The output will contain only one value from list2 that is ‘Bash is a scripting language’.\n",
    "\n",
    "# Filter a list of string using another list and custom function\n",
    "# This example shows how a list of string can be filtered by using another list \n",
    "# and the custom filter function. The script contains two list variables \n",
    "# named list1 and list2. The custom filter function will find out the common values of both list variables.\n",
    "\n",
    "# # Declare two list variables\n",
    "# list1 = ['90', '67', '34', '55', '12', '87', '32']\n",
    "# list2 = ['9', '90', '38', '45', '12', '20']\n",
    " \n",
    "# # Declare a funtion to filter data from the first list\n",
    "# def Filter(list1, list2):\n",
    "#     return [n for n in list1 if\n",
    "#              any(m in n for m in list2)]\n",
    " \n",
    "# # Print the list data before filter and after filter\n",
    "# print(\"The content of list1:\", list1)\n",
    "# print(\"The content of list2:\", list2)\n",
    "# print(\"The data after filter\",Filter(list1, list2))\n",
    "# Output:\n",
    "\n",
    "# Run the script. 90 and 12 values exist in both list variables. The following output will be generated after running the script.\n",
    "\n",
    "\n",
    "\n",
    "# Filter a list of string using regular expression\n",
    "# List is filtered by using all() and any() methods in the previous two examples. A regular expression is used in this example to filter the data from a list. A regular expression is a pattern by which any data can be searched or matched. ‘re’ module is used in python to apply regular expression in the script. Here, a list is declared with subject codes. A regular expression is used to filter those subject codes that start with the word, ‘CSE’. ‘^‘ symbol is used in regular expression patterns to search at the starting of the text.\n",
    "\n",
    "# # Import re module to use regular expression\n",
    "# import re\n",
    " \n",
    "# # Declare the list contains subject code\n",
    "# sublist = ['CSE-407', 'PHY-101', 'CSE-101', 'ENG-102', 'MAT-202']\n",
    "\n",
    "# # Declare the filter function\n",
    "# def Filter(datalist):\n",
    "#     # Search data based on regular expression in the list\n",
    "#     return [val for val in datalist\n",
    "#         if re.search(r'^CSE', val)]\n",
    "\n",
    "# # Print the filter data\n",
    "# print(Filter(sublist))\n",
    "# Output:\n",
    "\n",
    "# Run the script. sublist variable contains two values that start with ‘CSE’. The following output will appear after running the script.\n",
    "\n",
    "\n",
    "\n",
    "# Filter a list of string using lamda expression\n",
    "# This example shows the use of lamda expression to filter data from a list of strings. Here, a list variable named search_word is used to filter content from a text variable named text. The content of the text is converted into a list named, text_word based on space by using split() method. lamda expression will omit those values from the text_word that exist in search_word and store the filtered values in a variable by adding space.\n",
    "\n",
    "# # Declare a list that contains the search word\n",
    "# search_word = [\"Teach\", \"Code\", \"Programming\", \"Blog\"]\n",
    "\n",
    "# # Define the text where the word from the list will search\n",
    "# text = \"Learn Python Programming from Linux Hint Blog\"\n",
    "\n",
    "# # Split the text based on space and store the words in a list\n",
    "# text_word = text.split()\n",
    "\n",
    "# # Using lambda expression filter the data\n",
    "# filter_text = ' '.join((filter(lambda val: val not i\n",
    "# n search_word, text_word)))\n",
    "\n",
    "# # Print text before filtering and after filtering\n",
    "# print(\"\\nText before filtering:\\n\", text)\n",
    "# print(\"Text after filtering:\\n\", filter_text)\n",
    "# Output:\n",
    "\n",
    "# Run the script. The following output will appear after running the script.\n",
    "\n",
    "\n",
    "\n",
    "# Filter a list of string using filter() method\n",
    "# filter() method accepts two parameters. The first parameter takes a function name or None and the second parameter takes the name of the list variable as values. filter() method stores those data from the list if it returns true, otherwise, it discards the data. Here, None is given as the first parameter value. All values without false will be retrieved from the list as filtered data.\n",
    "\n",
    "# # Declare a list of mix data\n",
    "# listData = ['Hello', 200, 1, 'World', False, True, '0']\n",
    " \n",
    "# # Call filter() method with None and a list\n",
    "# filteredData = filter(None, listData)\n",
    " \n",
    "# # Print the list after filtering the data\n",
    "# print('The list after filtering:')\n",
    "# for val in filteredData:\n",
    "#     print(val)\n",
    "# Output:\n",
    "\n",
    "# Run the script. The list contains only one false value that will be omitted in the filtered data. The following output will appear after running the script.\n",
    "\n",
    "\n",
    "\n",
    "# Conclusion:\n",
    "# Filtering is helpful when you need to search and retrieve particular values from a list. I, hope, the above examples will help the readers to understand the ways of filtering data from a list of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# higher high , higher low .. probapilty whats happend next\n",
    "\n",
    "# go to weekly and find trend lines like atomusdt logarithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas generalities 21:37\n",
    "\n",
    "# if a column type is object; most likly its strings\n",
    "# pandas df could host another df inside of it\n",
    "\n",
    "df.columns\n",
    "df.index\n",
    "df.values # outputs an array\n",
    "df.values[0] # array which is the first row of df\n",
    "\n",
    "df['col1'] # return a series\n",
    "df[['col1']] # returs a df\n",
    "\n",
    "df.drop(['B', 'C'], axis=1)\n",
    "df.drop(columns=['B', 'C'])\n",
    "# Drop a row by index\n",
    "df.drop([0, 1])\n",
    "df.drop(index='cow', columns='small')\n",
    "\n",
    "df.drop() # works with rows; so change the axis if you wanna work columns\n",
    "df.drop(['col1', 'col2'], axis='columns') \n",
    "\n",
    "df[['col1', 'col2']].drop_duplicates()\n",
    "\n",
    "df.sort_values(['col1', 'col2'])\n",
    "df.sort_values('col1', ascending=False)\n",
    "\n",
    "\n",
    "df.describe()\n",
    "gdf = df.groupby('col1')\n",
    "df.groupby('col1').agg({'col1': 'mean'})\n",
    "df.groupby('col1').sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'llo s, n_'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# strings manipulation\n",
    "\n",
    "string1=\"ETH/USDT\"\n",
    "string1.replace(\"/\",\"\") \n",
    "\n",
    "# Creation\n",
    "word = \"Hello World\"\n",
    "\n",
    "# Accessing\n",
    "# Use [ ] to access characters in a string\n",
    "\n",
    "word = \"Hello World\"\n",
    "letter=word[0]\n",
    "\n",
    "# Length\n",
    "len(word)\n",
    "# 11\n",
    "\n",
    "# Finding\n",
    "# word = \"Hello World\">>> print word.count('l') # count how many times l is in the string\n",
    "# 3\n",
    "\n",
    "# >>> print word.find(\"H\") # find the word H in the string\n",
    "# 0\n",
    "\n",
    "# >>> print word.index(\"World\") # find the letters World in the string\n",
    "# 6\n",
    "# Count\n",
    "# s = \"Count, the number of spaces\"\n",
    "\n",
    "# >>> print s.count(' ')\n",
    "# 8\n",
    "# Slicing\n",
    "# Use [ # : # ] to get set of letter\n",
    "\n",
    "# Keep in mind that python, as many other languages, starts to count from 0!!\n",
    "\n",
    "# word = \"Hello World\"\n",
    "\n",
    "# print word[0] #get one char of the word\n",
    "# print word[0:1] #get one char of the word (same as above)\n",
    "# print word[0:3] #get the first three char\n",
    "# print word[:3] #get the first three char\n",
    "# print word[-3:] #get the last three char\n",
    "# print word[3:] #get all but the three first char\n",
    "# print word[:-3] #get all but the three last character\n",
    "\n",
    "# word = \"Hello World\"\n",
    "\n",
    "# word[start:end] # items start through end-1\n",
    "# word[start:] # items start through the rest of the list\n",
    "# word[:end] # items from the beginning through end-1\n",
    "# word[:] # a copy of the whole list\n",
    "# Split Strings\n",
    "# word = \"Hello World\"\n",
    "\n",
    "# >>> word.split(' ') # Split on whitespace\n",
    "# ['Hello', 'World']\n",
    "# Startswith / Endswith\n",
    "# word = \"hello world\"\n",
    "\n",
    "# >>> word.startswith(\"H\")\n",
    "# True\n",
    "\n",
    "# >>> word.endswith(\"d\")\n",
    "# True\n",
    "\n",
    "# >>> word.endswith(\"w\")\n",
    "# False\n",
    "# Repeat Strings\n",
    "# print \".\"* 10 # prints ten dots\n",
    "\n",
    "# >>> print \".\" * 10\n",
    "# ..........\n",
    "# Replacing\n",
    "# word = \"Hello World\"\n",
    "\n",
    "# >>> word.replace(\"Hello\", \"Goodbye\")\n",
    "# 'Goodbye World'\n",
    "# Changing Upper and Lower Case Strings\n",
    "# string = \"Hello World\"\n",
    "\n",
    "# >>> print string.upper()\n",
    "# HELLO WORLD\n",
    "\n",
    "# >>> print string.lower()\n",
    "# hello world\n",
    "\n",
    "# >>> print string.title()\n",
    "# Hello World\n",
    "\n",
    "# >>> print string.capitalize()\n",
    "# Hello world\n",
    "\n",
    "# >>> print string.swapcase()\n",
    "# hELLO wORLD\n",
    "# Reversing\n",
    "# string = \"Hello World\"\n",
    "\n",
    "# >>> print ' '.join(reversed(string))\n",
    "# d l r o W o l l e H\n",
    "# Strip\n",
    "# Python strings have the strip(), lstrip(), rstrip() methods for removing\n",
    "# any character from both ends of a string.\n",
    "\n",
    "# If the characters to be removed are not specified then white-space will be removed\n",
    "\n",
    "# word = \"Hello World\"\n",
    "# Strip off newline characters from end of the string\n",
    "\n",
    "# >>> print word.strip('\n",
    "# ')\n",
    "# Hello World\n",
    "\n",
    "# strip() #removes from both ends\n",
    "# lstrip() #removes leading characters (Left-strip)\n",
    "# rstrip() #removes trailing characters (Right-strip)\n",
    "\n",
    "# >>> word = \" xyz \"\n",
    "\n",
    "# >>> print word\n",
    "# xyz\n",
    "\n",
    "# >>> print word.strip()\n",
    "# xyz\n",
    "\n",
    "# >>> print word.lstrip()\n",
    "# xyz\n",
    "\n",
    "# >>> print word.rstrip()\n",
    "# xyz\n",
    "# Concatenation\n",
    "# To concatenate strings in Python use the “+” operator.\n",
    "\n",
    "# \"Hello \" + \"World\" # = \"Hello World\"\n",
    "# \"Hello \" + \"World\" + \"!\"# = \"Hello World!\"\n",
    "# Join\n",
    "# >>> print \":\".join(word) # #add a : between every char\n",
    "# H:e:l:l:o: :W:o:r:l:d\n",
    "\n",
    "# >>> print \" \".join(word) # add a whitespace between every char\n",
    "# H e l l o W o r l d\n",
    "\n",
    "# Testing\n",
    "# A string in Python can be tested for truth value.\n",
    "\n",
    "# The return type will be in Boolean value (True or False)\n",
    "\n",
    "# word = \"Hello World\"\n",
    "\n",
    "# word.isalnum() #check if all char are alphanumeric \n",
    "# word.isalpha() #check if all char in the string are alphabetic\n",
    "# word.isdigit() #test if string contains digits\n",
    "# word.istitle() #test if string contains title words\n",
    "# word.isupper() #test if string contains upper case\n",
    "# word.islower() #test if string contains lower case\n",
    "# word.isspace() #test if string contains spaces\n",
    "# word.endswith('d') #test if string endswith a d\n",
    "# word.startswith('H') #test if string startswith H\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "dict = {'A':[\"BTC/USDT\", \"ETH/USDT\", \"ATOM/USDT\", \"ANKR/USDT\"]}\n",
    "df = pd.DataFrame(dict)\n",
    "\n",
    "df['link'] = df['A'].apply(\n",
    "    lambda x: f'<a href=\"https://www.tradingview.com/chart/UOC7kIDx/?symbol=BINANCE%3A{x.replace(\"/\",\"\")}\">{x}</a>')\n",
    "\n",
    "# just print the link column\n",
    "# display(HTML(df[[\"link\"]].to_html(escape=False)))\n",
    "\n",
    "display(HTML(df.to_html(escape=False)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total[total[0]==18].index.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda\n",
    "# Simply put, a lambda function is just like any normal python function,\n",
    "# except that it has no name when defining it,\n",
    "# and it is contained in one line of code.\n",
    "\n",
    "# can only perform one expression.\n",
    "# It’s not possible to have multiple independent operations in one lambda function.\n",
    "\n",
    "#Normal python function\n",
    "def a_name(x):\n",
    "    return x+x\n",
    "\n",
    "#Lambda function\n",
    "lambda x: x+x\n",
    "\n",
    "# let’s look at situations when to use lambda functions. \n",
    "\n",
    "# 1.Scalar values\n",
    "\n",
    "# In the code below, the function was created and then immediately executed.\n",
    "# This is an example of an immediately invoked function expression or IIFE.\n",
    "\n",
    "(lambda x: x*2)(12)\n",
    "###Results\n",
    "24\n",
    "\n",
    "# Filter().\n",
    "\n",
    "#  This is a Python inbuilt library that returns only those values that fit certain criteria.\n",
    "#  The syntax is filter(function, iterable).\n",
    "#  The iterable can be any sequence such as a list, set, or series object (more below).\n",
    "\n",
    "# The example below filters a list for even numbers.\n",
    "#  Note that the filter function returns a ‘Filter object’ and you need to encapsulate it\n",
    "#  with a list to return the values.\n",
    "\n",
    "list_1 = [1,2,3,4,5,6,7,8,9]\n",
    "filter(lambda x: x%2==0, list_1)\n",
    "### Results\n",
    "# <filter at 0xf378982348>\n",
    "\n",
    "list(filter(lambda x: x%2==0, list_1))\n",
    "###Results\n",
    "[2, 4, 6, 8]\n",
    "\n",
    "# Map().\n",
    "\n",
    "# This is another inbuilt python library with the syntax map(function, iterable).\n",
    "# This returns a modified list where every value in the original list has been changed\n",
    "#  based on a function. The example below cubes every number in the list.\n",
    "\n",
    "list_1 = [1,2,3,4,5,6,7,8,9]\n",
    "cubed = map(lambda x: pow(x,3), list_1)\n",
    "list(cubed)\n",
    "###Results\n",
    "[1, 8, 27, 64, 125, 216, 343, 512, 729]\n",
    "\n",
    "#  Series object\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Luke','Gina','Sam','Emma'],\n",
    "    'Status': ['Father', 'Mother', 'Son', 'Daughter'],\n",
    "    'Birthyear': [1976, 1984, 2013, 2016],\n",
    "})\n",
    "\n",
    "# Lambda with Apply() function by Pandas. \n",
    "# This function applies an operation to every element of the column.\n",
    "# To get the current age of each member, we subtract their birth year from the current year.\n",
    "# In the lambda function below, x refers to a value in the birthyear column,\n",
    "# and the expression is 2021(current year) minus the value.\n",
    "\n",
    "df['age'] = df['Birthyear'].apply(lambda x: 2021-x)\n",
    "df\n",
    "#    Name    Status  Birthyear  age\n",
    "# 0  Luke    Father       1976   45\n",
    "# 1  Gina    Mother       1984   37\n",
    "# 2   Sam       Son       2013    8\n",
    "# 3  Emma  Daughter       2016    5\n",
    "\n",
    "# Lambda with Python’s Filter() function. \n",
    "# This takes 2 arguments; one is a lambda function with a condition expression,\n",
    "#  two an iterable which for us is a series object.\n",
    "#  It returns a list of values that satisfy the condition.\n",
    "\n",
    "list(filter(lambda x: x>18, df['age']))\n",
    "###Results\n",
    "[45, 37]\n",
    "\n",
    "\n",
    "# Lambda with Map() function by Pandas.\n",
    "# Map works very much like apply() in that it modifies values of a column based on the expression.\n",
    "#Double the age of everyone\n",
    "df['double_age'] = df['age'].map(lambda x: x*2)\n",
    "\n",
    "\n",
    "# We can also perform conditional operations that return different values based on certain criteria.\n",
    "# The code below returns ‘Male’ if the Status value is father or son,\n",
    "# and returns ‘Female’ otherwise. \n",
    "# Note that apply and map are interchangeable in this context.\n",
    "#Conditional Lambda statement\n",
    "df['Gender'] = df['Status'].map(lambda x: 'Male' if x=='father' or x=='son' else 'Female')\n",
    "\n",
    "# 4. Lambda on Dataframe object\n",
    "\n",
    "# I mostly use Lambda functions on specific columns (series object)\n",
    "# rather than the entire data frame, unless I want to modify the entire data frame with one expression.\n",
    "# For example rounding all values to 1 decimal place,\n",
    "# in which case all the columns have to be float or int datatypes because round() can’t work on strings.\n",
    "df.apply(lambda x:round(x,1))\n",
    "# Returns an error if some columns are not numeric\n",
    "# In the example below, we use apply on a dataframe and select the columns to modify in the Lambda function.\n",
    "# Note that we must use axis=1 here so that the expression is applied column-wise.\n",
    "# convert to lower-case\n",
    "df[['Name','Status']] = df.apply(lambda x: x[['Name','Status']].str.lower(), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function numpy.polyfit () \n",
    "# finds the best fit line by minimizing the sum of squared error. \n",
    "# give it a chart and it will give you its equation_if it was polonomial_\n",
    "\n",
    "# This method accepts three parameters:\n",
    "# x – input data\n",
    "# y- output data\n",
    "# Polynomial degree value (integer)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "# Generating data\n",
    "# We will create some mock data to explore polynomial fitting\n",
    "# The unknown function we are trying to fit\n",
    "f = lambda x: (x-3)**2\n",
    "\n",
    "# Generating the sample points\n",
    "# lispace(0,5,20) : 20 numbers between 0 and 5; seperated equaly \n",
    "x = np.linspace(0, 5, 20)\n",
    "\n",
    "# Adding gaussian noise to x and f(x)\n",
    "np.random.seed(123456)\n",
    "noise_x = np.random.normal(0, .1, len(x))\n",
    "noise_y = np.random.normal(0, .5, len(x))\n",
    "data_x = x + noise_x\n",
    "data_y = f(x) + noise_y\n",
    "\n",
    "# Let’s assume that this is our starting point. \n",
    "# We are given some data and we wish to fit a polynomial. \n",
    "# I always recommend plotting you data first!\n",
    "\n",
    "plt.plot(data_x, data_y, 'o')\n",
    "\n",
    "\n",
    "# Polynomial Fitting\n",
    "# The np.polyfit function is exactly what we want. \n",
    "# Given a set of xy points and a polynomial degree, \n",
    "# np.polyfit returns the coefficients of the best fit. \n",
    "# Lets see it in action\n",
    "\n",
    "coeff = np.polyfit(data_x, data_y, deg=2)\n",
    "print(coeff)\n",
    "# [ 0.94969091 -5.707748    8.46536612]\n",
    "\n",
    "# The coefficients are returned from highest to lowest power\n",
    "# (note: The order of the coefficients is important). \n",
    "# We can now use these coefficients to evaluate the polynomial.\n",
    "\n",
    "# Polynomial Function\n",
    "eq = lambda x: coeff[0]*x**2 + coeff[1]*x + coeff[2]\n",
    "\n",
    "# Points to evaluate _ start and end \n",
    "xp = np.linspace(min(data_x), max(data_x), 500)\n",
    "\n",
    "# Plotting result\n",
    "plt.plot(data_x, data_y, 'o')\n",
    "plt.plot(xp, eq(xp), color='C2')\n",
    "\n",
    "\n",
    "# WAIT!!!\n",
    "# While what we have done has worked there is a flaw in our method. \n",
    "# By handcrafting the polynomial function we have lost flexibility. \n",
    "# If I want a 7th degree fit then we waste lots of time writing up a 7th degree polynomial function \n",
    "# and introduce the possibility for errors. The np.poly1d function creates polynomial functions\n",
    "#  from the list of coefficients directly. Here the order matters \n",
    "#  and luckily np.poly1d expects the polynomial’s coefficients in decreasing powers \n",
    "#  which is exactly what np.polyfit returns. Lets create that 7th order polynomial fit\n",
    "\n",
    "p7 = np.poly1d(np.polyfit(data_x, data_y,  7))\n",
    "xp = np.linspace(min(data_x), max(data_x), 500)\n",
    "\n",
    "plt.plot(data_x, data_y, 'o')\n",
    "plt.plot(xp, p7(xp), color='C3')\n",
    "\n",
    "# Now we have a flexible procedure to do polynomial fitting. \n",
    "# We can put this procedure into a loop and plot many polynomial fits\n",
    "\n",
    "plt.plot(data_x, data_y, 'o')\n",
    "xp = np.linspace(min(data_x), max(data_x), 500)\n",
    "for degree in [1, 2, 10]:\n",
    "    eq = np.poly1d(np.polyfit(data_x, data_y,  degree))\n",
    "    plt.plot(xp, eq(xp), label='$p_{{{}}}$'.format(degree))\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy array vs python lists\n",
    "\n",
    "import numpy\n",
    "   \n",
    "# size of arrays and lists\n",
    "size = 1000000  \n",
    "   \n",
    "# declaring lists\n",
    "list1 = range(size)\n",
    "list2 = range(size)\n",
    "   \n",
    "# declaring arrays\n",
    "array1 = numpy.arange(size)  \n",
    "array2 = numpy.arange(size)\n",
    "   \n",
    "# multiplying  elements of both the lists and stored in another list\n",
    "resultantList = [(a * b) for a, b in zip(list1, list2)]\n",
    "\n",
    "# multiplying  elements of both the Numpy arrays and stored in another Numpy array \n",
    "resultantArray = array1 * array2\n",
    "   \n",
    "\n",
    "# declaring a list\n",
    "ls =[1, 2, 3]\n",
    "  \n",
    "# converting the list into a Numpy array\n",
    "arr = np.array([1, 2, 3])\n",
    "  \n",
    "\n",
    "# adding 4 to each element of list\n",
    "ls = ls + 4\n",
    "# TypeError\n",
    "# \"Lists don't support list + int\"\n",
    "  \n",
    "\n",
    "# adding 4 to each element of Numpy array\n",
    "arr = arr + 4\n",
    "# [5 6 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swap column\n",
    "\n",
    "df.loc[:, ['B', 'A']] = df[['A', 'B']].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing ranges with df[:3]\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dates = pd.date_range('1/1/2000', periods=8)\n",
    "\n",
    "df = pd.DataFrame(np.random.randn(8, 4),\n",
    "                  index=dates, columns=['A', 'B', 'C', 'D'])\n",
    "\n",
    "df\n",
    "# Out[3]: \n",
    "#                    A         B         C         D\n",
    "# 2000-01-01  0.469112 -0.282863 -1.509059 -1.135632\n",
    "# 2000-01-02  1.212112 -0.173215  0.119209 -1.044236\n",
    "# 2000-01-03 -0.861849 -2.104569 -0.494929  1.071804\n",
    "# 2000-01-04  0.721555 -0.706771 -1.039575  0.271860\n",
    "# 2000-01-05 -0.424972  0.567020  0.276232 -1.087401\n",
    "# 2000-01-06 -0.673690  0.113648 -1.478427  0.524988\n",
    "# 2000-01-07  0.404705  0.577046 -1.715002 -1.039268\n",
    "# 2000-01-08 -0.370647 -1.157892 -1.344312  0.844885\n",
    "\n",
    "s = df['A']\n",
    "\n",
    "s[dates[5]]\n",
    "# Out[5]: -0.6736897080883706\n",
    "\n",
    "# With Series, the syntax works exactly as with an ndarray,\n",
    "#  returning a slice of the values and the corresponding labels:\n",
    "s[:5]\n",
    "# Out[27]: \n",
    "# 2000-01-01    0.469112\n",
    "# 2000-01-02    1.212112\n",
    "# 2000-01-03   -0.861849\n",
    "# 2000-01-04    0.721555\n",
    "# 2000-01-05   -0.424972\n",
    "# Freq: D, Name: A, dtype: float64\n",
    "\n",
    "s[::2]\n",
    "# Out[28]: \n",
    "# 2000-01-01    0.469112\n",
    "# 2000-01-03   -0.861849\n",
    "# 2000-01-05   -0.424972\n",
    "# 2000-01-07    0.404705\n",
    "# Freq: 2D, Name: A, dtype: float64\n",
    "\n",
    "s[::-1]\n",
    "# Out[29]: \n",
    "# 2000-01-08   -0.370647\n",
    "# 2000-01-07    0.404705\n",
    "# 2000-01-06   -0.673690\n",
    "# 2000-01-05   -0.424972\n",
    "# 2000-01-04    0.721555\n",
    "# 2000-01-03   -0.861849\n",
    "# 2000-01-02    1.212112\n",
    "# 2000-01-01    0.469112\n",
    "# Freq: -1D, Name: A, dtype: float64\n",
    "# Note that setting works as well:\n",
    "\n",
    "s2 = s.copy()\n",
    "\n",
    "s2[:5] = 0\n",
    "\n",
    "s2\n",
    "# Out[32]: \n",
    "# 2000-01-01    0.000000\n",
    "# 2000-01-02    0.000000\n",
    "# 2000-01-03    0.000000\n",
    "# 2000-01-04    0.000000\n",
    "# 2000-01-05    0.000000\n",
    "# 2000-01-06   -0.673690\n",
    "# 2000-01-07    0.404705\n",
    "# 2000-01-08   -0.370647\n",
    "# Freq: D, Name: A, dtype: float64\n",
    "\n",
    "# With DataFrame, slicing inside of [] slices the rows. \n",
    "# This is provided largely as a convenience since it is such a common operation.\n",
    "df[:3]\n",
    "# Out[33]: \n",
    "#                    A         B         C         D\n",
    "# 2000-01-01  0.469112 -0.282863 -1.509059 -1.135632\n",
    "# 2000-01-02  1.212112 -0.173215  0.119209 -1.044236\n",
    "# 2000-01-03 -0.861849 -2.104569 -0.494929  1.071804\n",
    "\n",
    "df[::-1]\n",
    "# Out[34]: \n",
    "#                    A         B         C         D\n",
    "# 2000-01-08 -0.370647 -1.157892 -1.344312  0.844885\n",
    "# 2000-01-07  0.404705  0.577046 -1.715002 -1.039268\n",
    "# 2000-01-06 -0.673690  0.113648 -1.478427  0.524988\n",
    "# 2000-01-05 -0.424972  0.567020  0.276232 -1.087401\n",
    "# 2000-01-04  0.721555 -0.706771 -1.039575  0.271860\n",
    "# 2000-01-03 -0.861849 -2.104569 -0.494929  1.071804\n",
    "# 2000-01-02  1.212112 -0.173215  0.119209 -1.044236\n",
    "# 2000-01-01  0.469112 -0.282863 -1.509059 -1.135632"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if NA values are in data\n",
    "# only keep the rows that has volume!=0\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'v': [1,2,3,4,5], 'volume': [1,0,8,0,6]})\n",
    "df\n",
    "#    v  volume\n",
    "# 0  1       1\n",
    "# 1  2       0\n",
    "# 2  3       8\n",
    "# 3  4       0\n",
    "# 4  5       6\n",
    "\n",
    "# mask is a true or false \n",
    "mask = df['volume']!=0\n",
    "# when applying mask to df; only the true values will be consideres\n",
    "df = df[mask]\n",
    "df\n",
    "# v\tvolume\n",
    "# 0\t1\t1\n",
    "# 2\t3\t8\n",
    "# 4\t5\t6\n",
    "\n",
    "# a shorter version is\n",
    "df=df[df['volume']!=0]\n",
    "df\n",
    "# v\tvolume\n",
    "# 0\t1\t1\n",
    "# 2\t3\t8\n",
    "# 4\t5\t6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas.DataFrame.reset_index\n",
    "import pandas as pd\n",
    "df = pd.DataFrame([('bird', 389.0),\n",
    "                   ('bird', 24.0),\n",
    "                   ('mammal', 80.5),\n",
    "                   ('mammal', np.nan)],\n",
    "                  index=['falcon', 'parrot', 'lion', 'monkey'],\n",
    "                  columns=('class', 'max_speed'))\n",
    "df\n",
    "#          class  max_speed\n",
    "# falcon    bird      389.0\n",
    "# parrot    bird       24.0\n",
    "# lion    mammal       80.5\n",
    "# monkey  mammal        NaN\n",
    "\n",
    "# When we reset the index, the old index is added as a column, and a new sequential index is used:\n",
    "df.reset_index()\n",
    "#     index   class  max_speed\n",
    "# 0  falcon    bird      389.0\n",
    "# 1  parrot    bird       24.0\n",
    "# 2    lion  mammal       80.5\n",
    "# 3  monkey  mammal        NaN\n",
    "\n",
    "# We can use the drop parameter to avoid the old index being added as a column:\n",
    "df.reset_index(drop=True)\n",
    "#     class  max_speed\n",
    "# 0    bird      389.0\n",
    "# 1    bird       24.0\n",
    "# 2  mammal       80.5\n",
    "# 3  mammal        NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.isna().sum()\n",
    "# return how many nan in each column\n",
    "# or how many nan in each row (change axis)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({'a':[1,2,np.nan], 'b':[np.nan,1,np.nan]})\n",
    "df\n",
    "# \ta\tb\n",
    "# 0\t1.0\tNaN\n",
    "# 1\t2.0\t1.0\n",
    "# 2\tNaN\tNaN\n",
    "df.isna().sum()\n",
    "# a    1\n",
    "# b    2\n",
    "# dtype: int64\n",
    "df.isna().sum(axis=1)\n",
    "# 0    1\n",
    "# 1    0\n",
    "# 2    2\n",
    "# dtype: int64\n",
    "\n",
    "# isnull() also works\n",
    "df.isnull().sum(axis = 0)\n",
    "df.isnull().sum(axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({\n",
    "#     'col1': ['A', 'A', 'B', np.nan, 'D', 'C'],\n",
    "#     'col2': [2, 1, 9, 8, 7, 4],\n",
    "#     'col3': [0, 1, 9, 4, 2, 3],\n",
    "#     'col4': ['a', 'B', 'c', 'D', 'e', 'F']\n",
    "# })\n",
    "# df\n",
    "#   col1  col2  col3 col4\n",
    "# 0    A     2     0    a\n",
    "# 1    A     1     1    B\n",
    "# 2    B     9     9    c\n",
    "# 3  NaN     8     4    D\n",
    "# 4    D     7     2    e\n",
    "# 5    C     4     3    F\n",
    "# Sort by col1\n",
    "\n",
    "# df.sort_values(by=['col1'])\n",
    "#   col1  col2  col3 col4\n",
    "# 0    A     2     0    a\n",
    "# 1    A     1     1    B\n",
    "# 2    B     9     9    c\n",
    "# 5    C     4     3    F\n",
    "# 4    D     7     2    e\n",
    "# 3  NaN     8     4    D\n",
    "# Sort by multiple columns\n",
    "\n",
    "# df.sort_values(by=['col1', 'col2'])\n",
    "#   col1  col2  col3 col4\n",
    "# 1    A     1     1    B\n",
    "# 0    A     2     0    a\n",
    "# 2    B     9     9    c\n",
    "# 5    C     4     3    F\n",
    "# 4    D     7     2    e\n",
    "# 3  NaN     8     4    D\n",
    "# Sort Descending\n",
    "\n",
    "# df.sort_values(by='col1', ascending=False)\n",
    "#   col1  col2  col3 col4\n",
    "# 4    D     7     2    e\n",
    "# 5    C     4     3    F\n",
    "# 2    B     9     9    c\n",
    "# 0    A     2     0    a\n",
    "# 1    A     1     1    B\n",
    "# 3  NaN     8     4    D\n",
    "# Putting NAs first\n",
    "\n",
    "# df.sort_values(by='col1', ascending=False, na_position='first')\n",
    "#   col1  col2  col3 col4\n",
    "# 3  NaN     8     4    D\n",
    "# 4    D     7     2    e\n",
    "# 5    C     4     3    F\n",
    "# 2    B     9     9    c\n",
    "# 0    A     2     0    a\n",
    "# 1    A     1     1    B\n",
    "# Sorting with a key function\n",
    "\n",
    "# df.sort_values(by='col4', key=lambda col: col.str.lower())\n",
    "#    col1  col2  col3 col4\n",
    "# 0    A     2     0    a\n",
    "# 1    A     1     1    B\n",
    "# 2    B     9     9    c\n",
    "# 3  NaN     8     4    D\n",
    "# 4    D     7     2    e\n",
    "# 5    C     4     3    F\n",
    "# Natural sort with the key argument, using the natsort <https://github.com/SethMMorton/natsort> package.\n",
    "\n",
    "# df = pd.DataFrame({\n",
    "#    \"time\": ['0hr', '128hr', '72hr', '48hr', '96hr'],\n",
    "#    \"value\": [10, 20, 30, 40, 50]\n",
    "# })\n",
    "# df\n",
    "#     time  value\n",
    "# 0    0hr     10\n",
    "# 1  128hr     20\n",
    "# 2   72hr     30\n",
    "# 3   48hr     40\n",
    "# 4   96hr     50\n",
    "# from natsort import index_natsorted\n",
    "# df.sort_values(\n",
    "#    by=\"time\",\n",
    "#    key=lambda x: np.argsort(index_natsorted(df[\"time\"]))\n",
    "# )\n",
    "#     time  value\n",
    "# 0    0hr     10\n",
    "# 3   48hr     40\n",
    "# 2   72hr     30\n",
    "# 4   96hr     50\n",
    "# 1  128hr     20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://stackoverflow.com/questions/57770943/python-keyerror-date-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.getcwd()\n",
    "\n",
    "# os.path.join(outdir, outname)\n",
    "\n",
    "# os.path.exists(outdir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ccxt starter\n",
    "\n",
    "import ccxt, os\n",
    "\n",
    "exchange = ccxt.binance()\n",
    "exchange.load_markets()\n",
    "\n",
    "symbols = exchange.symbols\n",
    "\n",
    "# use bars[:-1] to avoid false signal espeacially in current candle\n",
    "# because ccxt gives the ongoing candle before they close _real time_\n",
    "# bars[:-3] will get less trades; but better quality\n",
    "\n",
    "def ccxt_data(symbol='ETH/USDT', timeframe ='4h', limit=111):\n",
    "    # using global is bad but i need it to get access to data variable in dataviewer\n",
    "    global data\n",
    "    # global fullname\n",
    "    \n",
    "    # 'ETH/USDT' to 'ETH_USDT'\n",
    "    m_symbol = symbol.replace(\"/\",\"_\")\n",
    "    # 'ETH_USDT_4h_111.csv'\n",
    "    outname = m_symbol+'_'+timeframe+'_'+f'{limit}'+'.csv'\n",
    "    outdir=os.getcwd()+f'/data/{timeframe}'\n",
    "    fullname = os.path.join(outdir, outname)    \n",
    "\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "\n",
    "    if not (os.path.exists(fullname)):\n",
    "\n",
    "        bars = exchange.fetch_ohlcv(symbol, timeframe=timeframe, limit=limit)\n",
    "        # must use bars[:-1] because arrgrelextrema will see the last candle wich have not closed yet\n",
    "        data = pd.DataFrame(bars[:-1], columns=['Time', 'Open', 'High', 'Low', 'Close', 'Volume'])\n",
    "        data['Time'] = pd.to_datetime(data['Time'], unit='ms')\n",
    "        data.set_index('Time', inplace=True)\n",
    "\n",
    "        data.to_csv(fullname) \n",
    "        # print('here')\n",
    "    \n",
    "    else:\n",
    "        tem_data = pd.read_csv(fullname, index_col='Time')\n",
    "        # last_candle_time=tem_data['Time'].max()\n",
    "        last_candle_time_plus=pd.to_datetime(tem_data.index[-1]) + pd.Timedelta(8, unit=\"h\")\n",
    "        if (last_candle_time_plus) >= pd.to_datetime(datetime.now()) :\n",
    "            data = tem_data\n",
    "        else:\n",
    "            bars = exchange.fetch_ohlcv(symbol, timeframe=timeframe, limit=limit)\n",
    "            data = pd.DataFrame(bars[:-1], columns=['Time', 'Open', 'High', 'Low', 'Close', 'Volume'])\n",
    "            data['Time'] = pd.to_datetime(data['Time'], unit='ms')\n",
    "            data.set_index('Time', inplace=True)\n",
    "\n",
    "            data.to_csv(fullname)\n",
    "            \n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing DataFrame\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Constructing DataFrame from a list\n",
    "mydict = [{'a': 1, 'b': 2, 'c': 3, 'd': 4},\n",
    "          {'a': 100, 'b': 200, 'c': 300, 'd': 400},\n",
    "          {'a': 1000, 'b': 2000, 'c': 3000, 'd': 4000 }]\n",
    "df = pd.DataFrame(mydict)\n",
    "# if you dont provide an index for df; pandas will give it the implicit index (0, 1, 2, ...)\n",
    "# mydict is actualy a list of dict\n",
    "# when converting a list into a df; the first element of the list is the first row which has the index 0\n",
    "# and you know the rest\n",
    "# in dict the key is the column name\n",
    "df\n",
    "#       a     b     c     d\n",
    "# 0     1     2     3     4\n",
    "# 1   100   200   300   400\n",
    "# 2  1000  2000  3000  4000\n",
    "\n",
    "# Constructing DataFrame from a dictionary.\n",
    "\n",
    "d = {'col1': [1, 2], 'col2': [3, 4]}\n",
    "df = pd.DataFrame(data=d)\n",
    "df\n",
    "#    col1  col2\n",
    "# 0     1     3\n",
    "# 1     2     4\n",
    "\n",
    "# Notice that the inferred dtype is int64.\n",
    "df.dtypes\n",
    "# col1    int64\n",
    "# col2    int64\n",
    "# dtype: object\n",
    "\n",
    "# To enforce a single dtype:\n",
    "df = pd.DataFrame(data=d, dtype=np.int8)\n",
    "# df.dtypes\n",
    "# col1    int8\n",
    "# col2    int8\n",
    "# dtype: object\n",
    "\n",
    "# Constructing DataFrame from numpy ndarray:\n",
    "df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n",
    "                   columns=['a', 'b', 'c'])\n",
    "df2\n",
    "#    a  b  c\n",
    "# 0  1  2  3\n",
    "# 1  4  5  6\n",
    "# 2  7  8  9\n",
    "\n",
    "# question = change dtype of a to i8 and keep the other at i4 ?\n",
    "\n",
    "# Constructing DataFrame from a numpy ndarray that has labeled columns:\n",
    "data = np.array([(1, 2, 3), (4, 5, 6), (7, 8, 9)],\n",
    "                dtype=[(\"a\", \"i4\"), (\"b\", \"i4\"), (\"c\", \"i4\")])\n",
    "df3 = pd.DataFrame(data, columns=['c', 'a'])\n",
    "df3\n",
    "#    c  a\n",
    "# 0  3  1\n",
    "# 1  6  4\n",
    "# 2  9  7\n",
    "\n",
    "# Constructing DataFrame from dataclass:\n",
    "from dataclasses import make_dataclass\n",
    "Point = make_dataclass(\"Point\", [(\"x\", int), (\"y\", int)])\n",
    "pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])\n",
    "#    x  y\n",
    "# 0  0  0\n",
    "# 1  0  3\n",
    "# 2  2  3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.iloc\n",
    "\n",
    ".iloc[] is primarily integer position based (from 0 to length-1 of the axis), \n",
    "but may also be used with a boolean array. \n",
    "\n",
    "Allowed inputs are:\n",
    "\n",
    "* An integer, e.g. 5.\n",
    "* A list or array of integers, e.g. [4, 3, 0].\n",
    "* A slice object with ints, e.g. 1:7.\n",
    "* A boolean array.\n",
    "* A callable function with one argument (the calling Series or DataFrame) and \n",
    "that returns valid output for indexing (one of the above). \n",
    "This is useful in method chains, when you don't have a reference to the calling object, \n",
    "but would like to base your selection on some value.\n",
    "\n",
    ".iloc will raise IndexError if a requested indexer is out-of-bounds, \n",
    "except slice indexers which allow out-of-bounds indexing\n",
    " (this conforms with python/numpy slice semantics). \"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "mydict = [{'a': 1, 'b': 2, 'c': 3, 'd': 4},\n",
    "          {'a': 100, 'b': 200, 'c': 300, 'd': 400},\n",
    "          {'a': 1000, 'b': 2000, 'c': 3000, 'd': 4000 }]\n",
    "df = pd.DataFrame(mydict)\n",
    "\n",
    "df\n",
    "#       a     b     c     d\n",
    "# 0     1     2     3     4\n",
    "# 1   100   200   300   400\n",
    "# 2  1000  2000  3000  4000\n",
    "\n",
    "# Indexing just the rows\n",
    "\n",
    "# With a scalar integer.\n",
    "type(df.iloc[0])\n",
    "# <class 'pandas.core.series.Series'>\n",
    "# here iloc returns a row in a series format which is a one column with index column; \n",
    "# but everything inversed; the columns names are the index now .. look the example below\n",
    "# there is a way to keep order, look the example below _the second one_\n",
    "\n",
    "df.iloc[0]\n",
    "# a    1\n",
    "# b    2\n",
    "# c    3\n",
    "# d    4\n",
    "# Name: 0, dtype: int64\n",
    "# notice that name is 0 which is the row name \n",
    "\n",
    "# With a list of integers.\n",
    "df.iloc[[0]]\n",
    "#    a  b  c  d\n",
    "# 0  1  2  3  4\n",
    "\n",
    "type(df.iloc[[0]])\n",
    "# <class 'pandas.core.frame.DataFrame'>\n",
    "\n",
    "df.iloc[[0, 1]]\n",
    "#      a    b    c    d\n",
    "# 0    1    2    3    4\n",
    "# 1  100  200  300  400\n",
    "\n",
    "# With a slice object.\n",
    "df.iloc[:3]\n",
    "#       a     b     c     d\n",
    "# 0     1     2     3     4\n",
    "# 1   100   200   300   400\n",
    "# 2  1000  2000  3000  4000\n",
    "\n",
    "# With a boolean mask the same length as the index.\n",
    "df.iloc[[True, False, True]]\n",
    "#       a     b     c     d\n",
    "# 0     1     2     3     4\n",
    "# 2  1000  2000  3000  4000\n",
    "\n",
    "# With a callable, useful in method chains. \n",
    "# The x passed to the lambda is the DataFrame being sliced. \n",
    "# This selects the rows whose index label even.\n",
    "df.iloc[lambda x: x.index % 2 == 0]\n",
    "#       a     b     c     d\n",
    "# 0     1     2     3     4\n",
    "# 2  1000  2000  3000  4000\n",
    "\n",
    "# Indexing both axes\n",
    "\n",
    "# You can mix the indexer types for the index and columns. \n",
    "# Use : to select the entire axis.With scalar integers.\n",
    "df.iloc[0, 1]\n",
    "# 2\n",
    "\n",
    "# With lists of integers.\n",
    "df.iloc[[0, 2], [1, 3]]\n",
    "#       b     d\n",
    "# 0     2     4\n",
    "# 2  2000  4000\n",
    "\n",
    "# With slice objects.\n",
    "df.iloc[1:3, 0:3]\n",
    "#       a     b     c\n",
    "# 1   100   200   300\n",
    "# 2  1000  2000  3000\n",
    "\n",
    "# With a boolean array whose length matches the columns.\n",
    "df.iloc[:, [True, False, True, False]]\n",
    "#       a     c\n",
    "# 0     1     3\n",
    "# 1   100   300\n",
    "# 2  1000  3000\n",
    "\n",
    "# With a callable function that expects the Series or DataFrame.\n",
    "df.iloc[:, lambda df: [0, 2]]\n",
    "#       a     c\n",
    "# 0     1     3\n",
    "# 1   100   300\n",
    "# 2  1000  3000\n",
    "\n",
    "# iloc returns a slice; then min() takes over\n",
    "step = 5\n",
    "minim = np.array([])\n",
    "for i in range(0, 55, step):\n",
    "    minim=np.append(minim, df.low.iloc[i:i+step].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.idxmin\n",
    "Return index of first occurrence of minimum over requested axis.\n",
    "\n",
    "NA/null values are excluded. \"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "# Consider a dataset containing food consumption in Argentina.\n",
    "\n",
    "df = pd.DataFrame({'consumption': [10.51, 103.11, 55.48],\n",
    "                   'co2_emissions': [37.2, 19.66, 1712]},\n",
    "                   index=['Pork', 'Wheat Products', 'Beef'])\n",
    "df\n",
    "#                 consumption  co2_emissions\n",
    "# Pork                  10.51         37.20\n",
    "# Wheat Products       103.11         19.66\n",
    "# Beef                  55.48       1712.00\n",
    "\n",
    "# By default, it returns the index for the minimum value in each column.\n",
    "df.idxmin()\n",
    "# consumption                Pork\n",
    "# co2_emissions    Wheat Products\n",
    "# dtype: object\n",
    "\n",
    "df['consumption'].idxmin()\n",
    "# 'Pork'\n",
    "\n",
    "# To return the index for the minimum value in each row, use axis=\"columns\".\n",
    "df.idxmin(axis=\"columns\")\n",
    "# Pork                consumption\n",
    "# Wheat Products    co2_emissions\n",
    "# Beef                consumption\n",
    "# dtype: object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy.append\n",
    "# Append values to the end of an array.\n",
    "\n",
    "np.append([1, 2, 3], [[4, 5, 6], [7, 8, 9]])\n",
    "# array([1, 2, 3, ..., 7, 8, 9])\n",
    "\n",
    "# When axis is specified, values must have the correct shape.\n",
    "np.append([[1, 2, 3], [4, 5, 6]], [[7, 8, 9]], axis=0)\n",
    "# array([[1, 2, 3],\n",
    "#        [4, 5, 6],\n",
    "#        [7, 8, 9]])\n",
    "\n",
    "np.append([[1, 2, 3], [4, 5, 6]], [7, 8, 9], axis=0)\n",
    "# Traceback (most recent call last):\n",
    "#     ...\n",
    "# ValueError: all the input arrays must have same number of dimensions, but\n",
    "# the array at index 0 has 2 dimension(s) and the array at index 1 has 1\n",
    "# dimension(s)\n",
    "\n",
    "my_list = []\n",
    "np.append(my_list, [[7, 8, 9]])\n",
    "# array([7., 8., 9.])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access dicts in a list\n",
    "\n",
    "# dataset = [dict(Images = 'img1', location = r'New/gfg.png'),\n",
    "#            dict(Images = 'img2', location = r'New/1.png'),\n",
    "#            dict(Images = 'img3', location = r'New/gfg2.png'),\n",
    "#            dict(Images = 'img4', location = r'New/oled.png'),\n",
    "#            dict(Images = 'img5', location = r'New/oled2.png')]\n",
    "\n",
    "# dataset[0]['Images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the difference between os.path.basename() and os.path.dirname()\n",
    "\n",
    "# Both functions use the os.path.split(path) function\n",
    "# to split the pathname path into a pair; (head, tail).\n",
    "\n",
    "# The os.path.dirname(path) function returns the head of the path.\n",
    "\n",
    "# E.g.: The dirname of '/foo/bar/item' is '/foo/bar'.\n",
    "\n",
    "# The os.path.basename(path) function returns the tail of the path.\n",
    "\n",
    "# E.g.: The basename of '/foo/bar/item' returns 'item'\n",
    "\n",
    "\n",
    "# Remember that if you replace item with item/, which is a directory,\n",
    "# then os.path.split('foo/bar/item/') returns ('foo/bar/item', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<a href=\"googlr.com/glr\">glr</a>'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Function to convert file path into clickable form.\n",
    "# def fun(path):\n",
    "    \n",
    "#     # returns the final component of a url\n",
    "#     f_url = os.path.basename(path)\n",
    "      \n",
    "#     # convert the url into link\n",
    "#     return '<a href=\"{}\">{}</a>'.format(path, f_url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if a and b and c and d and d\n",
    "\n",
    "\n",
    "# if a and b \\\n",
    "#     and c and d"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5a6e9528aa850de18c08131df015ab137a517634069ec846733f18057169b425"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('fintech': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
