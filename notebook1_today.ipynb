{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Notes about coding '''\n",
    "\"\"\" when you're done editing; copy the notebook file as backup \"\"\"\n",
    "\"\"\" each cell is a standalone \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Tricks \"\"\"\n",
    "\n",
    "\"\"\" to run only a small piece of code from within a cell; first run its dependecies than \n",
    "select the lines you want to run then press left mouse button and look for run selcted line  \n",
    "if teminal wont recognize code ; type py to run python inside it\"\"\"\n",
    "# line comment is ctrl + : \n",
    "# multi line comment is shift + alt + a\n",
    "# copy line(s) is shift+alt+arrow\n",
    "# \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(l) is <class list>\n",
    "\n",
    "# l.sort() ---> None\n",
    "\n",
    "# sorted(l) ---> works fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video 27:00 \n",
    "Y2Mate.is - Data Science Best Practices with pandas (PyCon 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"C:\\Users\\Grant\\Desktop\\work_git\\work\\data/1d/1INCHUSDT_1d.csv\")\n",
    "\n",
    "# Input In [4]\n",
    "#     df = pd.read_csv(\"C:\\Users\\Grant\\Desktop\\work_git\\work\\data/1d/1INCHUSDT_1d.csv\")\n",
    "#                                                                                     ^\n",
    "# SyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n",
    "\n",
    "# solution\n",
    "\n",
    "# df = pd.read_csv(\"C:\\\\Users\\Grant\\Desktop\\work_git\\work\\data/1d/1INCHUSDT_1d.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make yourself familliar with dataset before using it\n",
    "\n",
    "# df.dtypes\n",
    "# df.shape\n",
    "# df.head()\n",
    "# df.isna().sum()\n",
    "# somtimes you find (! ?) inside df cells which are not recognized as nan\n",
    "# so the solutin is to use replace method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Missing Values\n",
    "# Pandas provides isnull(), isna() functions to detect missing values. Both of them do the same thing.\n",
    "# df.isna() returns the dataframe with boolean values indicating missing values.\n",
    "\n",
    "# You can also choose to use notna() which is just the opposite of isna().\n",
    "# df.isna().any() returns a boolean value for each column. If there is at least one missing value in that column, the result is True.\n",
    "# df.isna().sum() returns the number of missing values in each column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to build a pandas DataFrame with a for-loop in Python\n",
    "\n",
    "\n",
    "# rows = []\n",
    "# for i in range(3):\n",
    "#      rows.append([i, i + 1])\n",
    "# print(rows)\n",
    "# OUTPUT\n",
    "# [[0, 1], [1, 2], [2, 3]]\n",
    "\n",
    "# df = pd.DataFrame(rows, columns=[\"A\", \"B\"])\n",
    "# print(df)\n",
    "# OUTPUT\n",
    "#    A  B\n",
    "# 0  0  1\n",
    "# 1  1  2\n",
    "# 2  2  3\n",
    "\n",
    "# Use a list comprehension for a more compact implementation.\n",
    "\n",
    "# rows = [[i, i+1] for i in range(3)]\n",
    "# df = pd.DataFrame(rows, columns=[\"A\", \"B\"])\n",
    "\n",
    "# print(df)\n",
    "# OUTPUT\n",
    "#    A  B\n",
    "# 0  0  1\n",
    "# 1  1  2\n",
    "# 2  2  3\n",
    "\n",
    "# USE COLUMN INDEXING TO BUILD A DATAFRAME WITH A FOR-LOOP\n",
    "\n",
    "# df = pd.DataFrame(columns=[\"A\", \"B\"])\n",
    "\n",
    "# for i in range(2):\n",
    "#     this_column = df.columns[i]\n",
    "#     df[this_column] = [i, i+1]\n",
    "\n",
    "# print(df)\n",
    "# OUTPUT\n",
    "#    A  B\n",
    "# 0  0  1\n",
    "# 1  1  2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to add element in Python to the end of list using list.insert?\n",
    "\n",
    "# You'll have to pass the new ordinal position to insert using len in this case:\n",
    "\n",
    "\n",
    "\n",
    "# a=[1,2,3,4]\n",
    "# a.insert(len(a),5)\n",
    "# a\n",
    "# [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to write a list to a file in Python\n",
    "# Writing a list to file saves the data contained in a list to a text file.\n",
    "# Each element from the list is written as a single line in the file.\n",
    "\n",
    "# USE file.write() TO WRITE A LIST TO A FILE\n",
    "# Call open(file, mode) with \"w\" as mode to open file for writing. \n",
    "# Use a for-loop to iterate over each element in a list. \n",
    "# Call file.write(data) with each element and a newline character as data to write it to file.\n",
    "\n",
    "# a_list = [\"abc\", \"def\", \"ghi\"]\n",
    "# textfile = open(\"a_file.txt\", \"w\")\n",
    "# for element in a_list:\n",
    "#     textfile.write(element + \"\\n\")\n",
    "# textfile.close()\n",
    "\n",
    "# A_FILE.TXT\n",
    "# abc\n",
    "# def\n",
    "# ghi\n",
    "# OTHER SOLUTIONS\n",
    "# Use pickle to write a list to a file\n",
    "\n",
    "# If the text file is only being saved for use later in the program, this method is more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({\n",
    "#     'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'],\n",
    "#     'style': ['cup', 'cup', 'cup', 'pack', 'pack'],\n",
    "#     'rating': [4, 4, 3.5, 15, 5]\n",
    "# })\n",
    "# df\n",
    "#     brand style  rating\n",
    "# 0  Yum Yum   cup     4.0\n",
    "# 1  Yum Yum   cup     4.0\n",
    "# 2  Indomie   cup     3.5\n",
    "# 3  Indomie  pack    15.0\n",
    "# 4  Indomie  pack     5.0\n",
    "# By default, it removes duplicate rows based on all columns.\n",
    "\n",
    "# df.drop_duplicates()\n",
    "#     brand style  rating\n",
    "# 0  Yum Yum   cup     4.0\n",
    "# 2  Indomie   cup     3.5\n",
    "# 3  Indomie  pack    15.0\n",
    "# 4  Indomie  pack     5.0\n",
    "# To remove duplicates on specific column(s), use subset.\n",
    "\n",
    "# df.drop_duplicates(subset=['brand'])\n",
    "#     brand style  rating\n",
    "# 0  Yum Yum   cup     4.0\n",
    "# 2  Indomie   cup     3.5\n",
    "# To remove duplicates and keep last occurrences, use keep.\n",
    "\n",
    "# df.drop_duplicates(subset=['brand', 'style'], keep='last')\n",
    "#     brand style  rating\n",
    "# 1  Yum Yum   cup     4.0\n",
    "# 2  Indomie   cup     3.5\n",
    "# 4  Indomie  pack     5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index.dropna(how='any')\n",
    "\n",
    "# Return Index without NA/NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(dict(age=[5, 6, np.NaN],\n",
    "#                    born=[pd.NaT, pd.Timestamp('1939-05-27'),\n",
    "#                          pd.Timestamp('1940-04-25')],\n",
    "#                    name=['Alfred', 'Batman', ''],\n",
    "#                    toy=[None, 'Batmobile', 'Joker']))\n",
    "# df\n",
    "#    age       born    name        toy\n",
    "# 0  5.0        NaT  Alfred       None\n",
    "# 1  6.0 1939-05-27  Batman  Batmobile\n",
    "# 2  NaN 1940-04-25              Joker\n",
    "# df.isna()\n",
    "#      age   born   name    toy\n",
    "# 0  False   True  False   True\n",
    "# 1  False  False  False  False\n",
    "# 2   True  False  False  False\n",
    "# Show which entries in a Series are NA.\n",
    "\n",
    "# ser = pd.Series([5, 6, np.NaN])\n",
    "# ser\n",
    "# 0    5.0\n",
    "# 1    6.0\n",
    "# 2    NaN\n",
    "# dtype: float64\n",
    "# ser.isna()\n",
    "# 0    False\n",
    "# 1    False\n",
    "# 2     True\n",
    "# dtype: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(dict(age=[5, 6, np.NaN],\n",
    "#                    born=[pd.NaT, pd.Timestamp('1939-05-27'),\n",
    "#                          pd.Timestamp('1940-04-25')],\n",
    "#                    name=['Alfred', 'Batman', ''],\n",
    "#                    toy=[None, 'Batmobile', 'Joker']))\n",
    "# df\n",
    "#    age       born    name        toy\n",
    "# 0  5.0        NaT  Alfred       None\n",
    "# 1  6.0 1939-05-27  Batman  Batmobile\n",
    "# 2  NaN 1940-04-25              Joker\n",
    "# df.notna()\n",
    "#      age   born  name    toy\n",
    "# 0   True  False  True  False\n",
    "# 1   True   True  True   True\n",
    "# 2  False   True  True   True\n",
    "# Show which entries in a Series are not NA.\n",
    "\n",
    "# ser = pd.Series([5, 6, np.NaN])\n",
    "# ser\n",
    "# 0    5.0\n",
    "# 1    6.0\n",
    "# 2    NaN\n",
    "# dtype: float64\n",
    "# ser.notna()\n",
    "# 0     True\n",
    "# 1     True\n",
    "# 2    False\n",
    "# dtype: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n",
    "#                    [3, 4, np.nan, 1],\n",
    "#                    [np.nan, np.nan, np.nan, np.nan],\n",
    "#                    [np.nan, 3, np.nan, 4]],\n",
    "#                   columns=list(\"ABCD\"))\n",
    "# df\n",
    "#      A    B   C    D\n",
    "# 0  NaN  2.0 NaN  0.0\n",
    "# 1  3.0  4.0 NaN  1.0\n",
    "# 2  NaN  NaN NaN  NaN\n",
    "# 3  NaN  3.0 NaN  4.0\n",
    "# Replace all NaN elements with 0s.\n",
    "\n",
    "# df.fillna(0)\n",
    "#      A    B    C    D\n",
    "# 0  0.0  2.0  0.0  0.0\n",
    "# 1  3.0  4.0  0.0  1.0\n",
    "# 2  0.0  0.0  0.0  0.0\n",
    "# 3  0.0  3.0  0.0  4.0\n",
    "# We can also propagate non-null values forward or backward.\n",
    "\n",
    "# df.fillna(method=\"ffill\")\n",
    "#      A    B   C    D\n",
    "# 0  NaN  2.0 NaN  0.0\n",
    "# 1  3.0  4.0 NaN  1.0\n",
    "# 2  3.0  4.0 NaN  1.0\n",
    "# 3  3.0  3.0 NaN  4.0\n",
    "# Replace all NaN elements in column ‘A’, ‘B’, ‘C’, and ‘D’, with 0, 1, 2, and 3 respectively.\n",
    "\n",
    "# values = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3}\n",
    "# df.fillna(value=values)\n",
    "#      A    B    C    D\n",
    "# 0  0.0  2.0  2.0  0.0\n",
    "# 1  3.0  4.0  2.0  1.0\n",
    "# 2  0.0  1.0  2.0  3.0\n",
    "# 3  0.0  3.0  2.0  4.0\n",
    "# Only replace the first NaN element.\n",
    "\n",
    "# df.fillna(value=values, limit=1)\n",
    "#      A    B    C    D\n",
    "# 0  0.0  2.0  2.0  0.0\n",
    "# 1  3.0  4.0  NaN  1.0\n",
    "# 2  NaN  1.0  NaN  3.0\n",
    "# 3  NaN  3.0  NaN  4.0\n",
    "# When filling using a DataFrame, replacement happens along the same column names and same indices\n",
    "\n",
    "# df2 = pd.DataFrame(np.zeros((4, 4)), columns=list(\"ABCE\"))\n",
    "# df.fillna(df2)\n",
    "#      A    B    C    D\n",
    "# 0  0.0  2.0  0.0  0.0\n",
    "# 1  3.0  4.0  0.0  1.0\n",
    "# 2  0.0  0.0  0.0  NaN\n",
    "# 3  0.0  3.0  0.0  4.0\n",
    "# Note that column D is not affected since it is not present in df2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({\"name\": ['Alfred', 'Batman', 'Catwoman'],\n",
    "#                    \"toy\": [np.nan, 'Batmobile', 'Bullwhip'],\n",
    "#                    \"born\": [pd.NaT, pd.Timestamp(\"1940-04-25\"),\n",
    "#                             pd.NaT]})\n",
    "# df\n",
    "#        name        toy       born\n",
    "# 0    Alfred        NaN        NaT\n",
    "# 1    Batman  Batmobile 1940-04-25\n",
    "# 2  Catwoman   Bullwhip        NaT\n",
    "\n",
    "# Drop the rows where at least one element is missing.\n",
    "\n",
    "# df.dropna()\n",
    "#      name        toy       born\n",
    "# 1  Batman  Batmobile 1940-04-25\n",
    "\n",
    "# Drop the columns where at least one element is missing.\n",
    "\n",
    "# df.dropna(axis='columns')\n",
    "#        name\n",
    "# 0    Alfred\n",
    "# 1    Batman\n",
    "# 2  Catwoman\n",
    "\n",
    "# Drop the rows where all elements are missing.\n",
    "\n",
    "# df.dropna(how='all')\n",
    "#        name        toy       born\n",
    "# 0    Alfred        NaN        NaT\n",
    "# 1    Batman  Batmobile 1940-04-25\n",
    "# 2  Catwoman   Bullwhip        NaT\n",
    "\n",
    "# Keep only the rows with at least 2 non-NA values.\n",
    "\n",
    "# df.dropna(thresh=2)\n",
    "#        name        toy       born\n",
    "# 1    Batman  Batmobile 1940-04-25\n",
    "# 2  Catwoman   Bullwhip        NaT\n",
    "\n",
    "# Define in which columns to look for missing values.\n",
    "\n",
    "# df.dropna(subset=['name', 'toy'])\n",
    "#        name        toy       born\n",
    "# 1    Batman  Batmobile 1940-04-25\n",
    "# 2  Catwoman   Bullwhip        NaT\n",
    "\n",
    "# Keep the DataFrame with valid entries in the same variable.\n",
    "\n",
    "# df.dropna(inplace=True)\n",
    "# df\n",
    "#      name        toy       born\n",
    "# 1  Batman  Batmobile 1940-04-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas.DataFrame.drop\n",
    "\n",
    "# Remove rows or columns by specifying label names and corresponding axis,\n",
    "# or by specifying directly index or column names.\n",
    "\n",
    "# df = pd.DataFrame(np.arange(12).reshape(3, 4),\n",
    "#                   columns=['A', 'B', 'C', 'D'])\n",
    "# df\n",
    "#    A  B   C   D\n",
    "# 0  0  1   2   3\n",
    "# 1  4  5   6   7\n",
    "# 2  8  9  10  11\n",
    "\n",
    "# Drop columns\n",
    "\n",
    "# df.drop(['B', 'C'], axis=1)\n",
    "#    A   D\n",
    "# 0  0   3\n",
    "# 1  4   7\n",
    "# 2  8  11\n",
    "\n",
    "# df.drop(columns=['B', 'C'])\n",
    "#    A   D\n",
    "# 0  0   3\n",
    "# 1  4   7\n",
    "# 2  8  11\n",
    "\n",
    "# Drop a row by index\n",
    "\n",
    "# df.drop([0, 1])\n",
    "#    A  B   C   D\n",
    "# 2  8  9  10  11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.exists(outdir):\n",
    "#     shutil.rmtree(outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nice way to automaticly update csv\n",
    "\n",
    "# c=pd.to_datetime(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "# b=pd.to_datetime(df.index[-1]) #+pd.to_timedelta(1, unit=\"d\")\n",
    "# if (c- b) < pd.to_timedelta(1, unit=\"d\"):\n",
    "#     print(c-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to find the dfs that are lagging behind in terms of last date \n",
    "# put last date of all dfs in a dict \n",
    "# than remove the ones that are diffrent than the majority\n",
    "# for example youll find \n",
    "# 200 entries are the same date\n",
    "# 23 diffrent dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install talib \n",
    "\n",
    "#  googel colab\n",
    "\n",
    "# !wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz\n",
    "# !tar xvzf ta-lib-0.4.0-src.tar.gz\n",
    "# import os\n",
    "# os.chdir('ta-lib') # Can't use !cd in co-lab\n",
    "# !./configure --prefix=/usr\n",
    "# !make\n",
    "# !make install\n",
    "# os.chdir('../')\n",
    "# !pip install TA-Lib\n",
    "\n",
    "\n",
    "# on windows \n",
    "\n",
    "# downlooad ta-lib-0.4.0-msvc and put it it c:\\talib\n",
    "# add it to path\n",
    "\n",
    "# Download package from here: https://www.lfd.uci.edu/~gohlke/pythonlibs/#ta-lib . \n",
    "\n",
    "#in terminal with virenv open\n",
    "# Cd to the downloaded file's dir\n",
    "# pip install TA_Lib‑0.4.19‑cp37‑cp37m‑win_amd64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# share variables between two jupyter notebooks:\n",
    "\n",
    "# jupyter notbook1:\n",
    "# var1\n",
    "# %store var1\n",
    "\n",
    "# jupyter notbook2:\n",
    "# %store -r var1\n",
    "# var1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# to make subfolders\n",
    "# os.makedirs\n",
    "\n",
    "# to make only one folder\n",
    "# os.mkdir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime.now().strftime('%Y-%m-%d_%H-%M-%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data['Time'] = pd.to_datetime(data['Time'], unit='ms')\n",
    "# data.set_index('Time', inplace=True)\n",
    "# data.to_csv(fullname) \n",
    "\n",
    "# tem_data = pd.read_csv(fullname, index_col='Time')\n",
    "# d = tem_data.index[-1] - datetime.now()\n",
    "\n",
    "# TypeError: unsupported operand type(s) for -: 'str' and 'datetime.datetime'\n",
    "\n",
    "# looks like when i save df as csv datetime turned into an str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the last candle in ccxt is it closed or still ongoing\n",
    "# the answer is that ccxt gives the last candle which has not closed yet\n",
    "# so use [:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l=np.array([1,2,3,4,5,6,7,6,5,4,3,2,3,4,5,6,7,8,9,10,11,12,13,12])\n",
    "# co = argrelextrema(l, np.greater, order=1)[0]\n",
    "# co\n",
    "# Output\n",
    "# array([ 6, 22], dtype=int64)\n",
    "# 6 and 22 are indexs coresspend to 7 and 13\n",
    "\n",
    "\n",
    "# l=np.array([1,2,3,4,5,6,7,6,5,4,3,2,3,4,5,6,7,8,9,10,11,12,13])\n",
    "# co = argrelextrema(l, np.greater, order=1)[0]\n",
    "# co\n",
    "# output\n",
    "# array([6], dtype=int64)\n",
    "\n",
    "# after removing the last digit \"12\" we find that argrelextream coudnot regonize\n",
    "# the peak at '13' simply because it needs confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zoom plot without problem\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in functions must use timeframe=timeframe and limit=Limit \n",
    "\n",
    "# or the default take over and alot of problems arise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df is empty\n",
    "\n",
    "# if (df):\n",
    "#     print('hh')\n",
    "# else:\n",
    "#     print('else')\n",
    "\n",
    "\n",
    "# ValueError: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
    "\n",
    "# solution\n",
    "\n",
    "# if len(df):\n",
    "#     print('hh')\n",
    "# else:\n",
    "#     print('else')\n",
    "\n",
    "\n",
    "\n",
    "# or \n",
    "\n",
    "# if df.empty:\n",
    "#     print('hh')\n",
    "# else:\n",
    "#     print('else')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# virtual env\n",
    "# PS C:\\Users\\Grant\\virenv> py -m venv algo\n",
    "# PS C:\\Users\\Grant\\virenv> cd algo\n",
    "# PS C:\\Users\\Grant\\virenv\\algo> cd Scripts\n",
    "# PS C:\\Users\\Grant\\virenv\\algo\\Scripts> ./activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_loc : Get integer location (implicit index) , slice or boolean mask for requested label.\n",
    "# \n",
    "# search index\n",
    "# data.index.get_loc('2021-07-15 00:00:00')\n",
    "# \n",
    "# search df columns\n",
    "# data.get_loc('value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ISO 8601 Duration strings\n",
    "# pd.Timedelta(\"P0DT0H1M0S\")\n",
    "# Out[13]: Timedelta('0 days 00:01:00')\n",
    "\n",
    "# pd.Timedelta(\"P0DT0H0M0.000000123S\")\n",
    "# Out[14]: Timedelta('0 days 00:00:00.000000123')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index has no iloc\n",
    "\n",
    "# time in df is a numpy time not a python datetime; numpy time is considered as int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# always take a look at the data; because i had a problem with read csv i did not give it index col "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.codegrepper.com/code-examples/python/second+row+to+last+index+pandas\n",
    "\n",
    "# https://www.codegrepper.com/code-examples/python/pandas+how+to+get+last+index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/61116489/indexes-getting-unordered-when-numbers-are-sorted-in-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.pythontutorial.net/python-basics/python-check-if-file-exists/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://linuxize.com/post/python-get-change-current-working-directory/#:~:text=To%20find%20the%20current%20working,chdir(path)%20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/how-to-export-pandas-dataframe-to-csv-2038e43d9c03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save a webpage as pdf just look for print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     do something\n",
    "# except:\n",
    "#     print('2')\n",
    "#     try:\n",
    "#         print('1')\n",
    "#     except:\n",
    "#         print('0')\n",
    "\n",
    "# the last try execpt loop will not work and will give you no eror\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error\n",
    "# TypeError: '>' not supported between instances of 'NoneType' and 'NoneType'\n",
    "\n",
    "# this error means you are compairng number with nan \n",
    "# in my case i put 1d in the timeframe wich was alot for a new coin because \n",
    "# i was asking for 111 candles\n",
    "# so i change to 1 hr and voila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not a:\n",
    "#   print(\"List is empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in not in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/29700214/get-the-closest-datetime-from-a-list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # any all list comprehension\n",
    "\n",
    "# Python uses list data type to store multiple data in a sequential index. It works like a numeric array of other programming languages. filter() method is a very useful method of Python. One or more data values can be filtered from any string or list or dictionary in Python by using filter() method.  It filters data based on any particular condition. It stores data when the condition returns true and discard data when returns false. How the string data in a list can be filtered in Python is shown in this article by using different examples. You have to use Python 3+ to test the examples of this article.\n",
    "# Filter a list of string using another list\n",
    "# This example shows how the data in a list of string can be filtered without using any method. The list of the string is filtered here by using another list. Here, two list variables are declared with the name list1 and list2. The values of list2 is filtered by using the values of list1. The script will match the first word of each value of list2 with the values of list1 and print those values that don’t exist in list1.\n",
    "\n",
    "# # Declare two list variables\n",
    "# list1 = ['Perl', 'PHP', 'Java', 'ASP']\n",
    "# list2 = ['JavaScript is client-side scripting language',\n",
    "#          'PHP is a server-side scripting language',\n",
    "#          'Java is a programming language',\n",
    "#          'Bash is a scripting language']\n",
    " \n",
    "# # Filter the second list based on first list\n",
    "# filter_data = [x for x in list2 if\n",
    "#               all(y not in x for y in list1)]\n",
    " \n",
    "# # Print list data before filter and after filter\n",
    "# print(\"The content of the first list:\", list1)\n",
    "# print(\"The content of the second list:\", list2)\n",
    "# print(\"The content of the second list after filter:\", filter_data)\n",
    "# Output:\n",
    "\n",
    "# Run the script. Here, list1 does not contain the word ‘Bash’. The output will contain only one value from list2 that is ‘Bash is a scripting language’.\n",
    "\n",
    "# Filter a list of string using another list and custom function\n",
    "# This example shows how a list of string can be filtered by using another list and the custom filter function. The script contains two list variables named list1 and list2. The custom filter function will find out the common values of both list variables.\n",
    "\n",
    "# # Declare two list variables\n",
    "# list1 = ['90', '67', '34', '55', '12', '87', '32']\n",
    "# list2 = ['9', '90', '38', '45', '12', '20']\n",
    " \n",
    "# # Declare a funtion to filter data from the first list\n",
    "# def Filter(list1, list2):\n",
    "#     return [n for n in list1 if\n",
    "#              any(m in n for m in list2)]\n",
    " \n",
    "# # Print the list data before filter and after filter\n",
    "# print(\"The content of list1:\", list1)\n",
    "# print(\"The content of list2:\", list2)\n",
    "# print(\"The data after filter\",Filter(list1, list2))\n",
    "# Output:\n",
    "\n",
    "# Run the script. 90 and 12 values exist in both list variables. The following output will be generated after running the script.\n",
    "\n",
    "\n",
    "\n",
    "# Filter a list of string using regular expression\n",
    "# List is filtered by using all() and any() methods in the previous two examples. A regular expression is used in this example to filter the data from a list. A regular expression is a pattern by which any data can be searched or matched. ‘re’ module is used in python to apply regular expression in the script. Here, a list is declared with subject codes. A regular expression is used to filter those subject codes that start with the word, ‘CSE’. ‘^‘ symbol is used in regular expression patterns to search at the starting of the text.\n",
    "\n",
    "# # Import re module to use regular expression\n",
    "# import re\n",
    " \n",
    "# # Declare the list contains subject code\n",
    "# sublist = ['CSE-407', 'PHY-101', 'CSE-101', 'ENG-102', 'MAT-202']\n",
    "\n",
    "# # Declare the filter function\n",
    "# def Filter(datalist):\n",
    "#     # Search data based on regular expression in the list\n",
    "#     return [val for val in datalist\n",
    "#         if re.search(r'^CSE', val)]\n",
    "\n",
    "# # Print the filter data\n",
    "# print(Filter(sublist))\n",
    "# Output:\n",
    "\n",
    "# Run the script. sublist variable contains two values that start with ‘CSE’. The following output will appear after running the script.\n",
    "\n",
    "\n",
    "\n",
    "# Filter a list of string using lamda expression\n",
    "# This example shows the use of lamda expression to filter data from a list of strings. Here, a list variable named search_word is used to filter content from a text variable named text. The content of the text is converted into a list named, text_word based on space by using split() method. lamda expression will omit those values from the text_word that exist in search_word and store the filtered values in a variable by adding space.\n",
    "\n",
    "# # Declare a list that contains the search word\n",
    "# search_word = [\"Teach\", \"Code\", \"Programming\", \"Blog\"]\n",
    "\n",
    "# # Define the text where the word from the list will search\n",
    "# text = \"Learn Python Programming from Linux Hint Blog\"\n",
    "\n",
    "# # Split the text based on space and store the words in a list\n",
    "# text_word = text.split()\n",
    "\n",
    "# # Using lambda expression filter the data\n",
    "# filter_text = ' '.join((filter(lambda val: val not i\n",
    "# n search_word, text_word)))\n",
    "\n",
    "# # Print text before filtering and after filtering\n",
    "# print(\"\\nText before filtering:\\n\", text)\n",
    "# print(\"Text after filtering:\\n\", filter_text)\n",
    "# Output:\n",
    "\n",
    "# Run the script. The following output will appear after running the script.\n",
    "\n",
    "\n",
    "\n",
    "# Filter a list of string using filter() method\n",
    "# filter() method accepts two parameters. The first parameter takes a function name or None and the second parameter takes the name of the list variable as values. filter() method stores those data from the list if it returns true, otherwise, it discards the data. Here, None is given as the first parameter value. All values without false will be retrieved from the list as filtered data.\n",
    "\n",
    "# # Declare a list of mix data\n",
    "# listData = ['Hello', 200, 1, 'World', False, True, '0']\n",
    " \n",
    "# # Call filter() method with None and a list\n",
    "# filteredData = filter(None, listData)\n",
    " \n",
    "# # Print the list after filtering the data\n",
    "# print('The list after filtering:')\n",
    "# for val in filteredData:\n",
    "#     print(val)\n",
    "# Output:\n",
    "\n",
    "# Run the script. The list contains only one false value that will be omitted in the filtered data. The following output will appear after running the script.\n",
    "\n",
    "\n",
    "\n",
    "# Conclusion:\n",
    "# Filtering is helpful when you need to search and retrieve particular values from a list. I, hope, the above examples will help the readers to understand the ways of filtering data from a list of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# higher high , higher low .. probapilty whats happend next\n",
    "\n",
    "# go to weekly and find trend lines like atomusdt logarithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas generalities 21:37\n",
    "\n",
    "# if a column type is object; most likly its strings\n",
    "# pandas df could host another df inside of it\n",
    "\n",
    "df.columns\n",
    "df.index\n",
    "df.values # outputs an array\n",
    "df.values[0] # array which is the first row of df\n",
    "\n",
    "df['col1'] # return a series\n",
    "df[['col1']] # returs a df\n",
    "\n",
    "df.drop(['B', 'C'], axis=1)\n",
    "df.drop(columns=['B', 'C'])\n",
    "# Drop a row by index\n",
    "df.drop([0, 1])\n",
    "df.drop(index='cow', columns='small')\n",
    "\n",
    "df.drop() # works with rows; so change the axis if you wanna work columns\n",
    "df.drop(['col1', 'col2'], axis='columns') \n",
    "\n",
    "df[['col1', 'col2']].drop_duplicates()\n",
    "\n",
    "df.sort_values(['col1', 'col2'])\n",
    "df.sort_values('col1', ascending=False)\n",
    "\n",
    "\n",
    "df.describe()\n",
    "gdf = df.groupby('col1')\n",
    "df.groupby('col1').agg({'col1': 'mean'})\n",
    "df.groupby('col1').sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'llo s, n_'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# strings manipulation\n",
    "\n",
    "string1=\"ETH/USDT\"\n",
    "string1.replace(\"/\",\"\") \n",
    "\n",
    "# Creation\n",
    "word = \"Hello World\"\n",
    "\n",
    "# Accessing\n",
    "# Use [ ] to access characters in a string\n",
    "\n",
    "word = \"Hello World\"\n",
    "letter=word[0]\n",
    "\n",
    "# Length\n",
    "len(word)\n",
    "# 11\n",
    "\n",
    "# Finding\n",
    "# word = \"Hello World\">>> print word.count('l') # count how many times l is in the string\n",
    "# 3\n",
    "\n",
    "# >>> print word.find(\"H\") # find the word H in the string\n",
    "# 0\n",
    "\n",
    "# >>> print word.index(\"World\") # find the letters World in the string\n",
    "# 6\n",
    "# Count\n",
    "# s = \"Count, the number of spaces\"\n",
    "\n",
    "# >>> print s.count(' ')\n",
    "# 8\n",
    "# Slicing\n",
    "# Use [ # : # ] to get set of letter\n",
    "\n",
    "# Keep in mind that python, as many other languages, starts to count from 0!!\n",
    "\n",
    "# word = \"Hello World\"\n",
    "\n",
    "# print word[0] #get one char of the word\n",
    "# print word[0:1] #get one char of the word (same as above)\n",
    "# print word[0:3] #get the first three char\n",
    "# print word[:3] #get the first three char\n",
    "# print word[-3:] #get the last three char\n",
    "# print word[3:] #get all but the three first char\n",
    "# print word[:-3] #get all but the three last character\n",
    "\n",
    "# word = \"Hello World\"\n",
    "\n",
    "# word[start:end] # items start through end-1\n",
    "# word[start:] # items start through the rest of the list\n",
    "# word[:end] # items from the beginning through end-1\n",
    "# word[:] # a copy of the whole list\n",
    "# Split Strings\n",
    "# word = \"Hello World\"\n",
    "\n",
    "# >>> word.split(' ') # Split on whitespace\n",
    "# ['Hello', 'World']\n",
    "# Startswith / Endswith\n",
    "# word = \"hello world\"\n",
    "\n",
    "# >>> word.startswith(\"H\")\n",
    "# True\n",
    "\n",
    "# >>> word.endswith(\"d\")\n",
    "# True\n",
    "\n",
    "# >>> word.endswith(\"w\")\n",
    "# False\n",
    "# Repeat Strings\n",
    "# print \".\"* 10 # prints ten dots\n",
    "\n",
    "# >>> print \".\" * 10\n",
    "# ..........\n",
    "# Replacing\n",
    "# word = \"Hello World\"\n",
    "\n",
    "# >>> word.replace(\"Hello\", \"Goodbye\")\n",
    "# 'Goodbye World'\n",
    "# Changing Upper and Lower Case Strings\n",
    "# string = \"Hello World\"\n",
    "\n",
    "# >>> print string.upper()\n",
    "# HELLO WORLD\n",
    "\n",
    "# >>> print string.lower()\n",
    "# hello world\n",
    "\n",
    "# >>> print string.title()\n",
    "# Hello World\n",
    "\n",
    "# >>> print string.capitalize()\n",
    "# Hello world\n",
    "\n",
    "# >>> print string.swapcase()\n",
    "# hELLO wORLD\n",
    "# Reversing\n",
    "# string = \"Hello World\"\n",
    "\n",
    "# >>> print ' '.join(reversed(string))\n",
    "# d l r o W o l l e H\n",
    "# Strip\n",
    "# Python strings have the strip(), lstrip(), rstrip() methods for removing\n",
    "# any character from both ends of a string.\n",
    "\n",
    "# If the characters to be removed are not specified then white-space will be removed\n",
    "\n",
    "# word = \"Hello World\"\n",
    "# Strip off newline characters from end of the string\n",
    "\n",
    "# >>> print word.strip('\n",
    "# ')\n",
    "# Hello World\n",
    "\n",
    "# strip() #removes from both ends\n",
    "# lstrip() #removes leading characters (Left-strip)\n",
    "# rstrip() #removes trailing characters (Right-strip)\n",
    "\n",
    "# >>> word = \" xyz \"\n",
    "\n",
    "# >>> print word\n",
    "# xyz\n",
    "\n",
    "# >>> print word.strip()\n",
    "# xyz\n",
    "\n",
    "# >>> print word.lstrip()\n",
    "# xyz\n",
    "\n",
    "# >>> print word.rstrip()\n",
    "# xyz\n",
    "# Concatenation\n",
    "# To concatenate strings in Python use the “+” operator.\n",
    "\n",
    "# \"Hello \" + \"World\" # = \"Hello World\"\n",
    "# \"Hello \" + \"World\" + \"!\"# = \"Hello World!\"\n",
    "# Join\n",
    "# >>> print \":\".join(word) # #add a : between every char\n",
    "# H:e:l:l:o: :W:o:r:l:d\n",
    "\n",
    "# >>> print \" \".join(word) # add a whitespace between every char\n",
    "# H e l l o W o r l d\n",
    "\n",
    "# Testing\n",
    "# A string in Python can be tested for truth value.\n",
    "\n",
    "# The return type will be in Boolean value (True or False)\n",
    "\n",
    "# word = \"Hello World\"\n",
    "\n",
    "# word.isalnum() #check if all char are alphanumeric \n",
    "# word.isalpha() #check if all char in the string are alphabetic\n",
    "# word.isdigit() #test if string contains digits\n",
    "# word.istitle() #test if string contains title words\n",
    "# word.isupper() #test if string contains upper case\n",
    "# word.islower() #test if string contains lower case\n",
    "# word.isspace() #test if string contains spaces\n",
    "# word.endswith('d') #test if string endswith a d\n",
    "# word.startswith('H') #test if string startswith H\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "dict = {'A':[\"BTC/USDT\", \"ETH/USDT\", \"ATOM/USDT\", \"ANKR/USDT\"]}\n",
    "df = pd.DataFrame(dict)\n",
    "\n",
    "df['link'] = df['A'].apply(\n",
    "    lambda x: f'<a href=\"https://www.tradingview.com/chart/UOC7kIDx/?symbol=BINANCE%3A{x.replace(\"/\",\"\")}\">{x}</a>')\n",
    "\n",
    "# just print the link column\n",
    "# display(HTML(df[[\"link\"]].to_html(escape=False)))\n",
    "\n",
    "display(HTML(df.to_html(escape=False)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda\n",
    "# Simply put, a lambda function is just like any normal python function,\n",
    "# except that it has no name when defining it,\n",
    "# and it is contained in one line of code.\n",
    "\n",
    "# can only perform one expression.\n",
    "# It’s not possible to have multiple independent operations in one lambda function.\n",
    "\n",
    "#Normal python function\n",
    "def a_name(x):\n",
    "    return x+x\n",
    "\n",
    "#Lambda function\n",
    "lambda x: x+x\n",
    "\n",
    "# let’s look at situations when to use lambda functions. \n",
    "\n",
    "# 1.Scalar values\n",
    "\n",
    "# In the code below, the function was created and then immediately executed.\n",
    "# This is an example of an immediately invoked function expression or IIFE.\n",
    "\n",
    "(lambda x: x*2)(12)\n",
    "###Results\n",
    "24\n",
    "\n",
    "# Filter().\n",
    "\n",
    "#  This is a Python inbuilt library that returns only those values that fit certain criteria.\n",
    "#  The syntax is filter(function, iterable).\n",
    "#  The iterable can be any sequence such as a list, set, or series object (more below).\n",
    "\n",
    "# The example below filters a list for even numbers.\n",
    "#  Note that the filter function returns a ‘Filter object’ and you need to encapsulate it\n",
    "#  with a list to return the values.\n",
    "\n",
    "list_1 = [1,2,3,4,5,6,7,8,9]\n",
    "filter(lambda x: x%2==0, list_1)\n",
    "### Results\n",
    "# <filter at 0xf378982348>\n",
    "\n",
    "list(filter(lambda x: x%2==0, list_1))\n",
    "###Results\n",
    "[2, 4, 6, 8]\n",
    "\n",
    "# Map().\n",
    "\n",
    "# This is another inbuilt python library with the syntax map(function, iterable).\n",
    "# This returns a modified list where every value in the original list has been changed\n",
    "#  based on a function. The example below cubes every number in the list.\n",
    "\n",
    "list_1 = [1,2,3,4,5,6,7,8,9]\n",
    "cubed = map(lambda x: pow(x,3), list_1)\n",
    "list(cubed)\n",
    "###Results\n",
    "[1, 8, 27, 64, 125, 216, 343, 512, 729]\n",
    "\n",
    "#  Series object\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Luke','Gina','Sam','Emma'],\n",
    "    'Status': ['Father', 'Mother', 'Son', 'Daughter'],\n",
    "    'Birthyear': [1976, 1984, 2013, 2016],\n",
    "})\n",
    "\n",
    "# Lambda with Apply() function by Pandas. \n",
    "# This function applies an operation to every element of the column.\n",
    "# To get the current age of each member, we subtract their birth year from the current year.\n",
    "# In the lambda function below, x refers to a value in the birthyear column,\n",
    "# and the expression is 2021(current year) minus the value.\n",
    "\n",
    "df['age'] = df['Birthyear'].apply(lambda x: 2021-x)\n",
    "df\n",
    "#    Name    Status  Birthyear  age\n",
    "# 0  Luke    Father       1976   45\n",
    "# 1  Gina    Mother       1984   37\n",
    "# 2   Sam       Son       2013    8\n",
    "# 3  Emma  Daughter       2016    5\n",
    "\n",
    "# Lambda with Python’s Filter() function. \n",
    "# This takes 2 arguments; one is a lambda function with a condition expression,\n",
    "#  two an iterable which for us is a series object.\n",
    "#  It returns a list of values that satisfy the condition.\n",
    "\n",
    "list(filter(lambda x: x>18, df['age']))\n",
    "###Results\n",
    "[45, 37]\n",
    "\n",
    "\n",
    "# Lambda with Map() function by Pandas.\n",
    "# Map works very much like apply() in that it modifies values of a column based on the expression.\n",
    "#Double the age of everyone\n",
    "df['double_age'] = df['age'].map(lambda x: x*2)\n",
    "\n",
    "\n",
    "# We can also perform conditional operations that return different values based on certain criteria.\n",
    "# The code below returns ‘Male’ if the Status value is father or son,\n",
    "# and returns ‘Female’ otherwise. \n",
    "# Note that apply and map are interchangeable in this context.\n",
    "#Conditional Lambda statement\n",
    "df['Gender'] = df['Status'].map(lambda x: 'Male' if x=='father' or x=='son' else 'Female')\n",
    "\n",
    "# 4. Lambda on Dataframe object\n",
    "\n",
    "# I mostly use Lambda functions on specific columns (series object)\n",
    "# rather than the entire data frame, unless I want to modify the entire data frame with one expression.\n",
    "# For example rounding all values to 1 decimal place,\n",
    "# in which case all the columns have to be float or int datatypes because round() can’t work on strings.\n",
    "df.apply(lambda x:round(x,1))\n",
    "# Returns an error if some columns are not numeric\n",
    "# In the example below, we use apply on a dataframe and select the columns to modify in the Lambda function.\n",
    "# Note that we must use axis=1 here so that the expression is applied column-wise.\n",
    "# convert to lower-case\n",
    "df[['Name','Status']] = df.apply(lambda x: x[['Name','Status']].str.lower(), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function numpy.polyfit () \n",
    "# finds the best fit line by minimizing the sum of squared error. \n",
    "# give it a chart and it will give you its equation_if it was polonomial_\n",
    "\n",
    "# This method accepts three parameters:\n",
    "# x – input data\n",
    "# y- output data\n",
    "# Polynomial degree value (integer)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "# Generating data\n",
    "# We will create some mock data to explore polynomial fitting\n",
    "# The unknown function we are trying to fit\n",
    "f = lambda x: (x-3)**2\n",
    "\n",
    "# Generating the sample points\n",
    "# lispace(0,5,20) : 20 numbers between 0 and 5; seperated equaly \n",
    "x = np.linspace(0, 5, 20)\n",
    "\n",
    "# Adding gaussian noise to x and f(x)\n",
    "np.random.seed(123456)\n",
    "noise_x = np.random.normal(0, .1, len(x))\n",
    "noise_y = np.random.normal(0, .5, len(x))\n",
    "data_x = x + noise_x\n",
    "data_y = f(x) + noise_y\n",
    "\n",
    "# Let’s assume that this is our starting point. \n",
    "# We are given some data and we wish to fit a polynomial. \n",
    "# I always recommend plotting you data first!\n",
    "\n",
    "plt.plot(data_x, data_y, 'o')\n",
    "\n",
    "\n",
    "# Polynomial Fitting\n",
    "# The np.polyfit function is exactly what we want. \n",
    "# Given a set of xy points and a polynomial degree, \n",
    "# np.polyfit returns the coefficients of the best fit. \n",
    "# Lets see it in action\n",
    "\n",
    "coeff = np.polyfit(data_x, data_y, deg=2)\n",
    "print(coeff)\n",
    "# [ 0.94969091 -5.707748    8.46536612]\n",
    "\n",
    "# The coefficients are returned from highest to lowest power\n",
    "# (note: The order of the coefficients is important). \n",
    "# We can now use these coefficients to evaluate the polynomial.\n",
    "\n",
    "# Polynomial Function\n",
    "eq = lambda x: coeff[0]*x**2 + coeff[1]*x + coeff[2]\n",
    "\n",
    "# Points to evaluate _ start and end \n",
    "xp = np.linspace(min(data_x), max(data_x), 500)\n",
    "\n",
    "# Plotting result\n",
    "plt.plot(data_x, data_y, 'o')\n",
    "plt.plot(xp, eq(xp), color='C2')\n",
    "\n",
    "\n",
    "# WAIT!!!\n",
    "# While what we have done has worked there is a flaw in our method. \n",
    "# By handcrafting the polynomial function we have lost flexibility. \n",
    "# If I want a 7th degree fit then we waste lots of time writing up a 7th degree polynomial function \n",
    "# and introduce the possibility for errors. The np.poly1d function creates polynomial functions\n",
    "#  from the list of coefficients directly. Here the order matters \n",
    "#  and luckily np.poly1d expects the polynomial’s coefficients in decreasing powers \n",
    "#  which is exactly what np.polyfit returns. Lets create that 7th order polynomial fit\n",
    "\n",
    "p7 = np.poly1d(np.polyfit(data_x, data_y,  7))\n",
    "xp = np.linspace(min(data_x), max(data_x), 500)\n",
    "\n",
    "plt.plot(data_x, data_y, 'o')\n",
    "plt.plot(xp, p7(xp), color='C3')\n",
    "\n",
    "# Now we have a flexible procedure to do polynomial fitting. \n",
    "# We can put this procedure into a loop and plot many polynomial fits\n",
    "\n",
    "plt.plot(data_x, data_y, 'o')\n",
    "xp = np.linspace(min(data_x), max(data_x), 500)\n",
    "for degree in [1, 2, 10]:\n",
    "    eq = np.poly1d(np.polyfit(data_x, data_y,  degree))\n",
    "    plt.plot(xp, eq(xp), label='$p_{{{}}}$'.format(degree))\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy array vs python lists\n",
    "\n",
    "import numpy\n",
    "   \n",
    "# size of arrays and lists\n",
    "size = 1000000  \n",
    "   \n",
    "# declaring lists\n",
    "list1 = range(size)\n",
    "list2 = range(size)\n",
    "   \n",
    "# declaring arrays\n",
    "array1 = numpy.arange(size)  \n",
    "array2 = numpy.arange(size)\n",
    "   \n",
    "# multiplying  elements of both the lists and stored in another list\n",
    "resultantList = [(a * b) for a, b in zip(list1, list2)]\n",
    "\n",
    "# multiplying  elements of both the Numpy arrays and stored in another Numpy array \n",
    "resultantArray = array1 * array2\n",
    "   \n",
    "\n",
    "# declaring a list\n",
    "ls =[1, 2, 3]\n",
    "  \n",
    "# converting the list into a Numpy array\n",
    "arr = np.array([1, 2, 3])\n",
    "  \n",
    "\n",
    "# adding 4 to each element of list\n",
    "ls = ls + 4\n",
    "# TypeError\n",
    "# \"Lists don't support list + int\"\n",
    "  \n",
    "\n",
    "# adding 4 to each element of Numpy array\n",
    "arr = arr + 4\n",
    "# [5 6 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swap column\n",
    "\n",
    "df.loc[:, ['B', 'A']] = df[['A', 'B']].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing ranges with df[:3]\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dates = pd.date_range('1/1/2000', periods=8)\n",
    "\n",
    "df = pd.DataFrame(np.random.randn(8, 4),\n",
    "                  index=dates, columns=['A', 'B', 'C', 'D'])\n",
    "\n",
    "df\n",
    "# Out[3]: \n",
    "#                    A         B         C         D\n",
    "# 2000-01-01  0.469112 -0.282863 -1.509059 -1.135632\n",
    "# 2000-01-02  1.212112 -0.173215  0.119209 -1.044236\n",
    "# 2000-01-03 -0.861849 -2.104569 -0.494929  1.071804\n",
    "# 2000-01-04  0.721555 -0.706771 -1.039575  0.271860\n",
    "# 2000-01-05 -0.424972  0.567020  0.276232 -1.087401\n",
    "# 2000-01-06 -0.673690  0.113648 -1.478427  0.524988\n",
    "# 2000-01-07  0.404705  0.577046 -1.715002 -1.039268\n",
    "# 2000-01-08 -0.370647 -1.157892 -1.344312  0.844885\n",
    "\n",
    "s = df['A']\n",
    "\n",
    "s[dates[5]]\n",
    "# Out[5]: -0.6736897080883706\n",
    "\n",
    "# With Series, the syntax works exactly as with an ndarray,\n",
    "#  returning a slice of the values and the corresponding labels:\n",
    "s[:5]\n",
    "# Out[27]: \n",
    "# 2000-01-01    0.469112\n",
    "# 2000-01-02    1.212112\n",
    "# 2000-01-03   -0.861849\n",
    "# 2000-01-04    0.721555\n",
    "# 2000-01-05   -0.424972\n",
    "# Freq: D, Name: A, dtype: float64\n",
    "\n",
    "s[::2]\n",
    "# Out[28]: \n",
    "# 2000-01-01    0.469112\n",
    "# 2000-01-03   -0.861849\n",
    "# 2000-01-05   -0.424972\n",
    "# 2000-01-07    0.404705\n",
    "# Freq: 2D, Name: A, dtype: float64\n",
    "\n",
    "s[::-1]\n",
    "# Out[29]: \n",
    "# 2000-01-08   -0.370647\n",
    "# 2000-01-07    0.404705\n",
    "# 2000-01-06   -0.673690\n",
    "# 2000-01-05   -0.424972\n",
    "# 2000-01-04    0.721555\n",
    "# 2000-01-03   -0.861849\n",
    "# 2000-01-02    1.212112\n",
    "# 2000-01-01    0.469112\n",
    "# Freq: -1D, Name: A, dtype: float64\n",
    "# Note that setting works as well:\n",
    "\n",
    "s2 = s.copy()\n",
    "\n",
    "s2[:5] = 0\n",
    "\n",
    "s2\n",
    "# Out[32]: \n",
    "# 2000-01-01    0.000000\n",
    "# 2000-01-02    0.000000\n",
    "# 2000-01-03    0.000000\n",
    "# 2000-01-04    0.000000\n",
    "# 2000-01-05    0.000000\n",
    "# 2000-01-06   -0.673690\n",
    "# 2000-01-07    0.404705\n",
    "# 2000-01-08   -0.370647\n",
    "# Freq: D, Name: A, dtype: float64\n",
    "\n",
    "# With DataFrame, slicing inside of [] slices the rows. \n",
    "# This is provided largely as a convenience since it is such a common operation.\n",
    "df[:3]\n",
    "# Out[33]: \n",
    "#                    A         B         C         D\n",
    "# 2000-01-01  0.469112 -0.282863 -1.509059 -1.135632\n",
    "# 2000-01-02  1.212112 -0.173215  0.119209 -1.044236\n",
    "# 2000-01-03 -0.861849 -2.104569 -0.494929  1.071804\n",
    "\n",
    "df[::-1]\n",
    "# Out[34]: \n",
    "#                    A         B         C         D\n",
    "# 2000-01-08 -0.370647 -1.157892 -1.344312  0.844885\n",
    "# 2000-01-07  0.404705  0.577046 -1.715002 -1.039268\n",
    "# 2000-01-06 -0.673690  0.113648 -1.478427  0.524988\n",
    "# 2000-01-05 -0.424972  0.567020  0.276232 -1.087401\n",
    "# 2000-01-04  0.721555 -0.706771 -1.039575  0.271860\n",
    "# 2000-01-03 -0.861849 -2.104569 -0.494929  1.071804\n",
    "# 2000-01-02  1.212112 -0.173215  0.119209 -1.044236\n",
    "# 2000-01-01  0.469112 -0.282863 -1.509059 -1.135632"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if NA values are in data\n",
    "# only keep the rows that has volume!=0\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'v': [1,2,3,4,5], 'volume': [1,0,8,0,6]})\n",
    "df\n",
    "#    v  volume\n",
    "# 0  1       1\n",
    "# 1  2       0\n",
    "# 2  3       8\n",
    "# 3  4       0\n",
    "# 4  5       6\n",
    "\n",
    "# mask is a true or false \n",
    "mask = df['volume']!=0\n",
    "# when applying mask to df; only the true values will be consideres\n",
    "df = df[mask]\n",
    "df\n",
    "# v\tvolume\n",
    "# 0\t1\t1\n",
    "# 2\t3\t8\n",
    "# 4\t5\t6\n",
    "\n",
    "# a shorter version is\n",
    "df=df[df['volume']!=0]\n",
    "df\n",
    "# v\tvolume\n",
    "# 0\t1\t1\n",
    "# 2\t3\t8\n",
    "# 4\t5\t6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas.DataFrame.reset_index\n",
    "import pandas as pd\n",
    "df = pd.DataFrame([('bird', 389.0),\n",
    "                   ('bird', 24.0),\n",
    "                   ('mammal', 80.5),\n",
    "                   ('mammal', np.nan)],\n",
    "                  index=['falcon', 'parrot', 'lion', 'monkey'],\n",
    "                  columns=('class', 'max_speed'))\n",
    "df\n",
    "#          class  max_speed\n",
    "# falcon    bird      389.0\n",
    "# parrot    bird       24.0\n",
    "# lion    mammal       80.5\n",
    "# monkey  mammal        NaN\n",
    "\n",
    "# When we reset the index, the old index is added as a column, and a new sequential index is used:\n",
    "df.reset_index()\n",
    "#     index   class  max_speed\n",
    "# 0  falcon    bird      389.0\n",
    "# 1  parrot    bird       24.0\n",
    "# 2    lion  mammal       80.5\n",
    "# 3  monkey  mammal        NaN\n",
    "\n",
    "# We can use the drop parameter to avoid the old index being added as a column:\n",
    "df.reset_index(drop=True)\n",
    "#     class  max_speed\n",
    "# 0    bird      389.0\n",
    "# 1    bird       24.0\n",
    "# 2  mammal       80.5\n",
    "# 3  mammal        NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.isna().sum()\n",
    "# return how many nan in each column\n",
    "# or how many nan in each row (change axis)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({'a':[1,2,np.nan], 'b':[np.nan,1,np.nan]})\n",
    "df\n",
    "# \ta\tb\n",
    "# 0\t1.0\tNaN\n",
    "# 1\t2.0\t1.0\n",
    "# 2\tNaN\tNaN\n",
    "df.isna().sum()\n",
    "# a    1\n",
    "# b    2\n",
    "# dtype: int64\n",
    "df.isna().sum(axis=1)\n",
    "# 0    1\n",
    "# 1    0\n",
    "# 2    2\n",
    "# dtype: int64\n",
    "\n",
    "# isnull() also works\n",
    "df.isnull().sum(axis = 0)\n",
    "df.isnull().sum(axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({\n",
    "#     'col1': ['A', 'A', 'B', np.nan, 'D', 'C'],\n",
    "#     'col2': [2, 1, 9, 8, 7, 4],\n",
    "#     'col3': [0, 1, 9, 4, 2, 3],\n",
    "#     'col4': ['a', 'B', 'c', 'D', 'e', 'F']\n",
    "# })\n",
    "# df\n",
    "#   col1  col2  col3 col4\n",
    "# 0    A     2     0    a\n",
    "# 1    A     1     1    B\n",
    "# 2    B     9     9    c\n",
    "# 3  NaN     8     4    D\n",
    "# 4    D     7     2    e\n",
    "# 5    C     4     3    F\n",
    "# Sort by col1\n",
    "\n",
    "# df.sort_values(by=['col1'])\n",
    "#   col1  col2  col3 col4\n",
    "# 0    A     2     0    a\n",
    "# 1    A     1     1    B\n",
    "# 2    B     9     9    c\n",
    "# 5    C     4     3    F\n",
    "# 4    D     7     2    e\n",
    "# 3  NaN     8     4    D\n",
    "# Sort by multiple columns\n",
    "\n",
    "# df.sort_values(by=['col1', 'col2'])\n",
    "#   col1  col2  col3 col4\n",
    "# 1    A     1     1    B\n",
    "# 0    A     2     0    a\n",
    "# 2    B     9     9    c\n",
    "# 5    C     4     3    F\n",
    "# 4    D     7     2    e\n",
    "# 3  NaN     8     4    D\n",
    "# Sort Descending\n",
    "\n",
    "# df.sort_values(by='col1', ascending=False)\n",
    "#   col1  col2  col3 col4\n",
    "# 4    D     7     2    e\n",
    "# 5    C     4     3    F\n",
    "# 2    B     9     9    c\n",
    "# 0    A     2     0    a\n",
    "# 1    A     1     1    B\n",
    "# 3  NaN     8     4    D\n",
    "# Putting NAs first\n",
    "\n",
    "# df.sort_values(by='col1', ascending=False, na_position='first')\n",
    "#   col1  col2  col3 col4\n",
    "# 3  NaN     8     4    D\n",
    "# 4    D     7     2    e\n",
    "# 5    C     4     3    F\n",
    "# 2    B     9     9    c\n",
    "# 0    A     2     0    a\n",
    "# 1    A     1     1    B\n",
    "# Sorting with a key function\n",
    "\n",
    "# df.sort_values(by='col4', key=lambda col: col.str.lower())\n",
    "#    col1  col2  col3 col4\n",
    "# 0    A     2     0    a\n",
    "# 1    A     1     1    B\n",
    "# 2    B     9     9    c\n",
    "# 3  NaN     8     4    D\n",
    "# 4    D     7     2    e\n",
    "# 5    C     4     3    F\n",
    "# Natural sort with the key argument, using the natsort <https://github.com/SethMMorton/natsort> package.\n",
    "\n",
    "# df = pd.DataFrame({\n",
    "#    \"time\": ['0hr', '128hr', '72hr', '48hr', '96hr'],\n",
    "#    \"value\": [10, 20, 30, 40, 50]\n",
    "# })\n",
    "# df\n",
    "#     time  value\n",
    "# 0    0hr     10\n",
    "# 1  128hr     20\n",
    "# 2   72hr     30\n",
    "# 3   48hr     40\n",
    "# 4   96hr     50\n",
    "# from natsort import index_natsorted\n",
    "# df.sort_values(\n",
    "#    by=\"time\",\n",
    "#    key=lambda x: np.argsort(index_natsorted(df[\"time\"]))\n",
    "# )\n",
    "#     time  value\n",
    "# 0    0hr     10\n",
    "# 3   48hr     40\n",
    "# 2   72hr     30\n",
    "# 4   96hr     50\n",
    "# 1  128hr     20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://stackoverflow.com/questions/57770943/python-keyerror-date-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.getcwd()\n",
    "\n",
    "# os.path.join(outdir, outname)\n",
    "\n",
    "# os.path.exists(outdir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ccxt starter\n",
    "\n",
    "import ccxt, os\n",
    "\n",
    "exchange = ccxt.binance()\n",
    "exchange.load_markets()\n",
    "\n",
    "symbols = exchange.symbols\n",
    "\n",
    "# use bars[:-1] to avoid false signal espeacially in current candle\n",
    "# because ccxt gives the ongoing candle before they close _real time_\n",
    "# bars[:-3] will get less trades; but better quality\n",
    "\n",
    "def ccxt_data(symbol='ETH/USDT', timeframe ='4h', limit=111):\n",
    "    # using global is bad but i need it to get access to data variable in dataviewer\n",
    "    global data\n",
    "    # global fullname\n",
    "    \n",
    "    # 'ETH/USDT' to 'ETH_USDT'\n",
    "    m_symbol = symbol.replace(\"/\",\"_\")\n",
    "    # 'ETH_USDT_4h_111.csv'\n",
    "    outname = m_symbol+'_'+timeframe+'_'+f'{limit}'+'.csv'\n",
    "    outdir=os.getcwd()+f'/data/{timeframe}'\n",
    "    fullname = os.path.join(outdir, outname)    \n",
    "\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "\n",
    "    if not (os.path.exists(fullname)):\n",
    "\n",
    "        bars = exchange.fetch_ohlcv(symbol, timeframe=timeframe, limit=limit)\n",
    "        # must use bars[:-1] because arrgrelextrema will see the last candle wich have not closed yet\n",
    "        data = pd.DataFrame(bars[:-1], columns=['Time', 'Open', 'High', 'Low', 'Close', 'Volume'])\n",
    "        data['Time'] = pd.to_datetime(data['Time'], unit='ms')\n",
    "        data.set_index('Time', inplace=True)\n",
    "\n",
    "        data.to_csv(fullname) \n",
    "        # print('here')\n",
    "    \n",
    "    else:\n",
    "        tem_data = pd.read_csv(fullname, index_col='Time')\n",
    "        # last_candle_time=tem_data['Time'].max()\n",
    "        last_candle_time_plus=pd.to_datetime(tem_data.index[-1]) + pd.Timedelta(8, unit=\"h\")\n",
    "        if (last_candle_time_plus) >= pd.to_datetime(datetime.now()) :\n",
    "            data = tem_data\n",
    "        else:\n",
    "            bars = exchange.fetch_ohlcv(symbol, timeframe=timeframe, limit=limit)\n",
    "            data = pd.DataFrame(bars[:-1], columns=['Time', 'Open', 'High', 'Low', 'Close', 'Volume'])\n",
    "            data['Time'] = pd.to_datetime(data['Time'], unit='ms')\n",
    "            data.set_index('Time', inplace=True)\n",
    "\n",
    "            data.to_csv(fullname)\n",
    "            \n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing DataFrame\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Constructing DataFrame from a list\n",
    "mydict = [{'a': 1, 'b': 2, 'c': 3, 'd': 4},\n",
    "          {'a': 100, 'b': 200, 'c': 300, 'd': 400},\n",
    "          {'a': 1000, 'b': 2000, 'c': 3000, 'd': 4000 }]\n",
    "df = pd.DataFrame(mydict)\n",
    "# if you dont provide an index for df; pandas will give it the implicit index (0, 1, 2, ...)\n",
    "# mydict is actualy a list of dict\n",
    "# when converting a list into a df; the first element of the list is the first row which has the index 0\n",
    "# and you know the rest\n",
    "# in dict the key is the column name\n",
    "df\n",
    "#       a     b     c     d\n",
    "# 0     1     2     3     4\n",
    "# 1   100   200   300   400\n",
    "# 2  1000  2000  3000  4000\n",
    "\n",
    "# Constructing DataFrame from a dictionary.\n",
    "\n",
    "d = {'col1': [1, 2], 'col2': [3, 4]}\n",
    "df = pd.DataFrame(data=d)\n",
    "df\n",
    "#    col1  col2\n",
    "# 0     1     3\n",
    "# 1     2     4\n",
    "\n",
    "# Notice that the inferred dtype is int64.\n",
    "df.dtypes\n",
    "# col1    int64\n",
    "# col2    int64\n",
    "# dtype: object\n",
    "\n",
    "# To enforce a single dtype:\n",
    "df = pd.DataFrame(data=d, dtype=np.int8)\n",
    "# df.dtypes\n",
    "# col1    int8\n",
    "# col2    int8\n",
    "# dtype: object\n",
    "\n",
    "# Constructing DataFrame from numpy ndarray:\n",
    "df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n",
    "                   columns=['a', 'b', 'c'])\n",
    "df2\n",
    "#    a  b  c\n",
    "# 0  1  2  3\n",
    "# 1  4  5  6\n",
    "# 2  7  8  9\n",
    "\n",
    "# question = change dtype of a to i8 and keep the other at i4 ?\n",
    "\n",
    "# Constructing DataFrame from a numpy ndarray that has labeled columns:\n",
    "data = np.array([(1, 2, 3), (4, 5, 6), (7, 8, 9)],\n",
    "                dtype=[(\"a\", \"i4\"), (\"b\", \"i4\"), (\"c\", \"i4\")])\n",
    "df3 = pd.DataFrame(data, columns=['c', 'a'])\n",
    "df3\n",
    "#    c  a\n",
    "# 0  3  1\n",
    "# 1  6  4\n",
    "# 2  9  7\n",
    "\n",
    "# Constructing DataFrame from dataclass:\n",
    "from dataclasses import make_dataclass\n",
    "Point = make_dataclass(\"Point\", [(\"x\", int), (\"y\", int)])\n",
    "pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])\n",
    "#    x  y\n",
    "# 0  0  0\n",
    "# 1  0  3\n",
    "# 2  2  3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.iloc\n",
    "\n",
    ".iloc[] is primarily integer position based (from 0 to length-1 of the axis), \n",
    "but may also be used with a boolean array. \n",
    "\n",
    "Allowed inputs are:\n",
    "\n",
    "* An integer, e.g. 5.\n",
    "* A list or array of integers, e.g. [4, 3, 0].\n",
    "* A slice object with ints, e.g. 1:7.\n",
    "* A boolean array.\n",
    "* A callable function with one argument (the calling Series or DataFrame) and \n",
    "that returns valid output for indexing (one of the above). \n",
    "This is useful in method chains, when you don't have a reference to the calling object, \n",
    "but would like to base your selection on some value.\n",
    "\n",
    ".iloc will raise IndexError if a requested indexer is out-of-bounds, \n",
    "except slice indexers which allow out-of-bounds indexing\n",
    " (this conforms with python/numpy slice semantics). \"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "mydict = [{'a': 1, 'b': 2, 'c': 3, 'd': 4},\n",
    "          {'a': 100, 'b': 200, 'c': 300, 'd': 400},\n",
    "          {'a': 1000, 'b': 2000, 'c': 3000, 'd': 4000 }]\n",
    "df = pd.DataFrame(mydict)\n",
    "\n",
    "df\n",
    "#       a     b     c     d\n",
    "# 0     1     2     3     4\n",
    "# 1   100   200   300   400\n",
    "# 2  1000  2000  3000  4000\n",
    "\n",
    "# Indexing just the rows\n",
    "\n",
    "# With a scalar integer.\n",
    "type(df.iloc[0])\n",
    "# <class 'pandas.core.series.Series'>\n",
    "# here iloc returns a row in a series format which is a one column with index column; \n",
    "# but everything inversed; the columns names are the index now .. look the example below\n",
    "# there is a way to keep order, look the example below _the second one_\n",
    "\n",
    "df.iloc[0]\n",
    "# a    1\n",
    "# b    2\n",
    "# c    3\n",
    "# d    4\n",
    "# Name: 0, dtype: int64\n",
    "# notice that name is 0 which is the row name \n",
    "\n",
    "# With a list of integers.\n",
    "df.iloc[[0]]\n",
    "#    a  b  c  d\n",
    "# 0  1  2  3  4\n",
    "\n",
    "type(df.iloc[[0]])\n",
    "# <class 'pandas.core.frame.DataFrame'>\n",
    "\n",
    "df.iloc[[0, 1]]\n",
    "#      a    b    c    d\n",
    "# 0    1    2    3    4\n",
    "# 1  100  200  300  400\n",
    "\n",
    "# With a slice object.\n",
    "df.iloc[:3]\n",
    "#       a     b     c     d\n",
    "# 0     1     2     3     4\n",
    "# 1   100   200   300   400\n",
    "# 2  1000  2000  3000  4000\n",
    "\n",
    "# With a boolean mask the same length as the index.\n",
    "df.iloc[[True, False, True]]\n",
    "#       a     b     c     d\n",
    "# 0     1     2     3     4\n",
    "# 2  1000  2000  3000  4000\n",
    "\n",
    "# With a callable, useful in method chains. \n",
    "# The x passed to the lambda is the DataFrame being sliced. \n",
    "# This selects the rows whose index label even.\n",
    "df.iloc[lambda x: x.index % 2 == 0]\n",
    "#       a     b     c     d\n",
    "# 0     1     2     3     4\n",
    "# 2  1000  2000  3000  4000\n",
    "\n",
    "# Indexing both axes\n",
    "\n",
    "# You can mix the indexer types for the index and columns. \n",
    "# Use : to select the entire axis.With scalar integers.\n",
    "df.iloc[0, 1]\n",
    "# 2\n",
    "\n",
    "# With lists of integers.\n",
    "df.iloc[[0, 2], [1, 3]]\n",
    "#       b     d\n",
    "# 0     2     4\n",
    "# 2  2000  4000\n",
    "\n",
    "# With slice objects.\n",
    "df.iloc[1:3, 0:3]\n",
    "#       a     b     c\n",
    "# 1   100   200   300\n",
    "# 2  1000  2000  3000\n",
    "\n",
    "# With a boolean array whose length matches the columns.\n",
    "df.iloc[:, [True, False, True, False]]\n",
    "#       a     c\n",
    "# 0     1     3\n",
    "# 1   100   300\n",
    "# 2  1000  3000\n",
    "\n",
    "# With a callable function that expects the Series or DataFrame.\n",
    "df.iloc[:, lambda df: [0, 2]]\n",
    "#       a     c\n",
    "# 0     1     3\n",
    "# 1   100   300\n",
    "# 2  1000  3000\n",
    "\n",
    "# iloc returns a slice; then min() takes over\n",
    "step = 5\n",
    "minim = np.array([])\n",
    "for i in range(0, 55, step):\n",
    "    minim=np.append(minim, df.low.iloc[i:i+step].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.idxmin\n",
    "Return index of first occurrence of minimum over requested axis.\n",
    "\n",
    "NA/null values are excluded. \"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "# Consider a dataset containing food consumption in Argentina.\n",
    "\n",
    "df = pd.DataFrame({'consumption': [10.51, 103.11, 55.48],\n",
    "                   'co2_emissions': [37.2, 19.66, 1712]},\n",
    "                   index=['Pork', 'Wheat Products', 'Beef'])\n",
    "df\n",
    "#                 consumption  co2_emissions\n",
    "# Pork                  10.51         37.20\n",
    "# Wheat Products       103.11         19.66\n",
    "# Beef                  55.48       1712.00\n",
    "\n",
    "# By default, it returns the index for the minimum value in each column.\n",
    "df.idxmin()\n",
    "# consumption                Pork\n",
    "# co2_emissions    Wheat Products\n",
    "# dtype: object\n",
    "\n",
    "df['consumption'].idxmin()\n",
    "# 'Pork'\n",
    "\n",
    "# To return the index for the minimum value in each row, use axis=\"columns\".\n",
    "df.idxmin(axis=\"columns\")\n",
    "# Pork                consumption\n",
    "# Wheat Products    co2_emissions\n",
    "# Beef                consumption\n",
    "# dtype: object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy.append\n",
    "# Append values to the end of an array.\n",
    "\n",
    "np.append([1, 2, 3], [[4, 5, 6], [7, 8, 9]])\n",
    "# array([1, 2, 3, ..., 7, 8, 9])\n",
    "\n",
    "# When axis is specified, values must have the correct shape.\n",
    "np.append([[1, 2, 3], [4, 5, 6]], [[7, 8, 9]], axis=0)\n",
    "# array([[1, 2, 3],\n",
    "#        [4, 5, 6],\n",
    "#        [7, 8, 9]])\n",
    "\n",
    "np.append([[1, 2, 3], [4, 5, 6]], [7, 8, 9], axis=0)\n",
    "# Traceback (most recent call last):\n",
    "#     ...\n",
    "# ValueError: all the input arrays must have same number of dimensions, but\n",
    "# the array at index 0 has 2 dimension(s) and the array at index 1 has 1\n",
    "# dimension(s)\n",
    "\n",
    "my_list = []\n",
    "np.append(my_list, [[7, 8, 9]])\n",
    "# array([7., 8., 9.])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5a6e9528aa850de18c08131df015ab137a517634069ec846733f18057169b425"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('fintech': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
